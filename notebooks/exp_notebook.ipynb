{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "310947b4",
   "metadata": {},
   "source": [
    "### 사전 준비 사항 \n",
    "\n",
    "#### (1) uv add (터미널)\n",
    "\n",
    "```bash\n",
    "uv add rank_bm25\n",
    "```\n",
    "\n",
    "#### (2) .env 파일 세팅\n",
    "```bash\n",
    "OPENAI_API_KEY = \"\"\n",
    "HF_TOKEN = \"\"\n",
    "```\n",
    "\n",
    "#### (3) pdf 파일 세팅\n",
    "pdf 파일 100개를 `data/raw/files` 에 위치합니다.  \n",
    "eval 파일(csv 2개, jsonl 1개)을 `data/raw/eval` 에 위치합니다.(*30개 파일 합친 버전)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d68e1fc",
   "metadata": {},
   "source": [
    "#### 실행 방법\n",
    "\n",
    "1. 처음 1회(커널 새로 시작): 처음부터 끝까지 순서대로 실행\n",
    "2. exp1 결과 저장 확인\n",
    "3. <실험 ID 변경> 셀의 exp_id 를 변경 후 새로운 실험 진행 (실험 결과 저장 확인 후 커널 재시작)  \n",
    "\\*커널 재시작하지 않는 경우, 실험 ID 변경 + 실험 진행 섹션 코드만 실행해도 됨.(OOM 발생 가능성이 있어 권장하지 않음.)\n",
    "4. 원하는 실험로 변경 및 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4365838c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\github\\codeit-part3-team4\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading weights: 100%|██████████| 391/391 [00:00<00:00, 881.26it/s, Materializing param=pooler.dense.weight]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold_evidence_df: (630, 5)\n",
      "gold_fields_df: (630, 4)\n",
      "questions_df: (311, 5)\n",
      "n_docs: 100\n"
     ]
    }
   ],
   "source": [
    "import json, re, unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from preprocess.pp_basic import docs, BASE_DIR, EVAL_DIR, GOLD_EVIDENCE_CSV, GOLD_FIELDS_JSONL\n",
    "from preprocess.rag_experiment import (\n",
    "    CONFIG, ExperimentSpec, load_questions_df, make_components, RAGExperiment\n",
    ")\n",
    "\n",
    "load_dotenv(find_dotenv(), override=False)\n",
    "client = OpenAI()\n",
    "\n",
    "# embed 모델은 커널에서 1번만 로드(중요)\n",
    "embed_model = SentenceTransformer(\"nlpai-lab/KoE5\")\n",
    "\n",
    "# gold 로드\n",
    "gold_evidence_df = pd.read_csv(GOLD_EVIDENCE_CSV)\n",
    "\n",
    "def load_gold_fields_jsonl(path):\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                rows.append(json.loads(line))\n",
    "    out = []\n",
    "    for r in rows:\n",
    "        iid = r[\"instance_id\"]\n",
    "        doc_id = r.get(\"doc_id\", \"\")\n",
    "        fields = r.get(\"fields\", {}) or {}\n",
    "        for k, v in fields.items():\n",
    "            out.append({\"instance_id\": iid, \"doc_id\": doc_id, \"field\": k, \"gold\": v})\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "gold_fields_df = load_gold_fields_jsonl(GOLD_FIELDS_JSONL)\n",
    "\n",
    "questions_df = load_questions_df()\n",
    "\n",
    "print(\"gold_evidence_df:\", gold_evidence_df.shape)\n",
    "print(\"gold_fields_df:\", gold_fields_df.shape)\n",
    "print(\"questions_df:\", questions_df.shape)\n",
    "print(\"n_docs:\", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3ef239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval docs: 30\n"
     ]
    }
   ],
   "source": [
    "# 평가 문서 필터(커널당 1회)\n",
    "def name_key(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFC\", str(s)).strip()\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "gold_doc_key_set = set(name_key(x) for x in gold_fields_df[\"doc_id\"].astype(str).unique())\n",
    "EVAL_DOCS = [p for p in docs if name_key(p.name) in gold_doc_key_set]\n",
    "\n",
    "print(\"Eval docs:\", len(EVAL_DOCS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e29b9a",
   "metadata": {},
   "source": [
    "### 실험 ID 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "841fa683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running spec: ExperimentSpec(exp_id=1, chunker='C1', retriever='R1', generator='G1')\n",
      "RUN_DOCS: 30\n"
     ]
    }
   ],
   "source": [
    "RUN_EXP_ID = 1   # 1~18\n",
    "N_DOCS = 5       # 디버깅은 1~5 추천, 전체는 None 또는 아래 라인 변경\n",
    "\n",
    "# N개 문서 또는 전체 문서 테스트\n",
    "# RUN_DOCS = EVAL_DOCS[:N_DOCS]\n",
    "RUN_DOCS = EVAL_DOCS\n",
    "\n",
    "# exp table (18개)\n",
    "SPECS = {\n",
    "    1:  (\"C1\",\"R1\",\"G1\"),  2:  (\"C1\",\"R1\",\"G2\"),\n",
    "    3:  (\"C1\",\"R2\",\"G1\"),  4:  (\"C1\",\"R2\",\"G2\"),\n",
    "    5:  (\"C1\",\"R3\",\"G1\"),  6:  (\"C1\",\"R3\",\"G2\"),\n",
    "    7:  (\"C2\",\"R1\",\"G1\"),  8:  (\"C2\",\"R1\",\"G2\"),\n",
    "    9:  (\"C2\",\"R2\",\"G1\"),  10: (\"C2\",\"R2\",\"G2\"),\n",
    "    11: (\"C2\",\"R3\",\"G1\"),  12: (\"C2\",\"R3\",\"G2\"),\n",
    "    13: (\"C3\",\"R1\",\"G1\"),  14: (\"C3\",\"R1\",\"G2\"),\n",
    "    15: (\"C3\",\"R2\",\"G1\"),  16: (\"C3\",\"R2\",\"G2\"),\n",
    "    17: (\"C3\",\"R3\",\"G1\"),  18: (\"C3\",\"R3\",\"G2\"),\n",
    "}\n",
    "\n",
    "c, r, g = SPECS[RUN_EXP_ID]\n",
    "spec = ExperimentSpec(exp_id=RUN_EXP_ID, chunker=c, retriever=r, generator=g)\n",
    "print(\"Running spec:\", spec)\n",
    "print(\"RUN_DOCS:\", len(RUN_DOCS))\n",
    "\n",
    "# (선택) 실험 컨텍스트 cap 조정하고 싶은 경우 주석 해제 및 수정\n",
    "# CONFIG[\"max_context_chars\"] = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18568f09",
   "metadata": {},
   "source": [
    "### 디버깅 사전 설정(선택)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82d566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (옵션) sentinel 모니터링용\n",
    "SENT_NOT_FOUND = \"NOT_FOUND\"\n",
    "SENT_GEN_FAIL = \"GEN_FAIL\"\n",
    "\n",
    "def count_sentinels(pred_map: dict) -> dict:\n",
    "    if not isinstance(pred_map, dict):\n",
    "        return {\"n_keys\": 0, \"n_not_found\": 0, \"n_gen_fail\": 0}\n",
    "\n",
    "    vals = [str(v).strip() for v in pred_map.values()]\n",
    "    vals_l = [v.lower() for v in vals]\n",
    "\n",
    "    n_nf = sum(v in {\"not_found\", \"notfound\"} for v in vals_l)\n",
    "    n_gf = sum(v == \"gen_fail\" for v in vals_l)\n",
    "    return {\"n_keys\": len(vals), \"n_not_found\": n_nf, \"n_gen_fail\": n_gf}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d607284f",
   "metadata": {},
   "source": [
    "### 실험 수행 및 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "521e9f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exp 1 docs:   7%|▋         | 2/30 [01:10<15:35, 33.41s/it]d:\\dev\\github\\codeit-part3-team4\\notebooks\\preprocess\\rag_experiment.py:527: RuntimeWarning: Mean of empty slice\n",
      "  \"ret_recall\": float(np.nanmean([x[\"recall\"] for x in r_list])),\n",
      "d:\\dev\\github\\codeit-part3-team4\\notebooks\\preprocess\\rag_experiment.py:528: RuntimeWarning: Mean of empty slice\n",
      "  \"ret_mrr\": float(np.nanmean([x[\"mrr\"] for x in r_list])),\n",
      "d:\\dev\\github\\codeit-part3-team4\\notebooks\\preprocess\\rag_experiment.py:531: RuntimeWarning: Mean of empty slice\n",
      "  \"gen_match\": float(np.nanmean([x[\"match\"] for x in g_list])),\n",
      "d:\\dev\\github\\codeit-part3-team4\\notebooks\\preprocess\\rag_experiment.py:532: RuntimeWarning: Mean of empty slice\n",
      "  \"gen_sim\": float(np.nanmean([x[\"sim\"] for x in g_list])),\n",
      "Exp 1 docs: 100%|██████████| 30/30 [15:50<00:00, 31.68s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_id</th>\n",
       "      <th>chunk</th>\n",
       "      <th>retriever</th>\n",
       "      <th>model</th>\n",
       "      <th>n_docs</th>\n",
       "      <th>ret_recall</th>\n",
       "      <th>ret_mrr</th>\n",
       "      <th>gen_fill</th>\n",
       "      <th>gen_match</th>\n",
       "      <th>gen_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C1</td>\n",
       "      <td>R1</td>\n",
       "      <td>G1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.7521</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>36.9342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exp_id chunk retriever model  n_docs  ret_recall  ret_mrr  gen_fill  \\\n",
       "0       1    C1        R1    G1      30      0.7521   0.3077       1.0   \n",
       "\n",
       "   gen_match  gen_sim  \n",
       "0     0.1833  36.9342  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: d:\\dev\\github\\codeit-part3-team4\\outputs\\exp01_explevel.csv\n"
     ]
    }
   ],
   "source": [
    "chunker, retriever, generator = make_components(spec, embed_model=embed_model, client=client)\n",
    "rag = RAGExperiment(chunker=chunker, retriever=retriever, generator=generator, questions_df=questions_df)\n",
    "\n",
    "rows = []\n",
    "for doc_path in tqdm(RUN_DOCS, desc=f\"Exp {spec.exp_id} docs\"):\n",
    "    m = rag.run_single_doc_metrics(\n",
    "        doc_path,\n",
    "        gold_fields_df=gold_fields_df,\n",
    "        gold_evidence_df=gold_evidence_df,\n",
    "        top_k=CONFIG[\"top_k\"],\n",
    "        sim_threshold=80,\n",
    "    )\n",
    "    m[\"exp_id\"] = spec.exp_id\n",
    "    m[\"chunker\"] = spec.chunker\n",
    "    m[\"retriever\"] = spec.retriever\n",
    "    m[\"generator\"] = spec.generator\n",
    "    rows.append(m)\n",
    "\n",
    "doc_df = pd.DataFrame(rows)\n",
    "\n",
    "# exp-level average\n",
    "avg = doc_df[[\"ret_recall\",\"ret_mrr\",\"gen_fill\",\"gen_match\",\"gen_sim\"]].mean(numeric_only=True)\n",
    "exp_df = pd.DataFrame([{\n",
    "    \"exp_id\": spec.exp_id,\n",
    "    \"chunk\": spec.chunker,\n",
    "    \"retriever\": spec.retriever,\n",
    "    \"model\": spec.generator,\n",
    "    \"n_docs\": len(doc_df),\n",
    "    **{k: float(avg[k]) for k in avg.index},\n",
    "}])\n",
    "\n",
    "display(exp_df.round(4))\n",
    "\n",
    "out_dir = BASE_DIR / \"outputs\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "exp_out = out_dir / f\"exp{spec.exp_id:02d}_explevel.csv\"\n",
    "exp_df.to_csv(exp_out, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved:\", exp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92b1d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pred_maps: 30 -> d:\\dev\\github\\codeit-part3-team4\\outputs\\exp01_pred_maps\n"
     ]
    }
   ],
   "source": [
    "# 문서별 pred_map 저장 (옵션)\n",
    "pred_dir = out_dir / f\"exp{spec.exp_id:02d}_pred_maps\"\n",
    "pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "saved = 0\n",
    "for _, row in doc_df.iterrows():\n",
    "    doc_id = str(row[\"doc_id\"])\n",
    "    pred_map = row.get(\"pred_map\", None)\n",
    "    if isinstance(pred_map, dict):\n",
    "        # 파일명 안전화\n",
    "        safe = re.sub(r\"[\\\\/:*?\\\"<>|]\", \"_\", doc_id)\n",
    "        path = pred_dir / f\"{safe}.json\"\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(pred_map, f, ensure_ascii=False, indent=2)\n",
    "        saved += 1\n",
    "\n",
    "print(\"Saved pred_maps:\", saved, \"->\", pred_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0d2889",
   "metadata": {},
   "source": [
    "### 디버깅(선택)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dce56f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_debug: {'model': 'gpt-5-mini', 'n_questions': 21, 'context_len': 4000, 'max_context_chars': 4000, 'prompt_len': 5856, 'response_status': 'completed', 'output_tokens': 556, 'output_text_repr': '\\'{\"project_name\":\"NOT_FOUND\",\"agency\":\"민속아카이브\",\"purpose\":\"NOT_FOUND\",\"budget\":\"NOT_FOUND\",\"contract_type\":\"NOT_FOUND\",\"deadline\":\"NOT_FOUND\",\"duration\":\"NOT_FOUND\",\"requirements_must\":\"시큐어 코딩 준수 및 웹 취약\\'', 'exception': None, 'parse_error': None}\n",
      "raw_text_len: 1267\n",
      "raw_text_preview:\n",
      " {\"project_name\":\"NOT_FOUND\",\"agency\":\"민속아카이브\",\"purpose\":\"NOT_FOUND\",\"budget\":\"NOT_FOUND\",\"contract_type\":\"NOT_FOUND\",\"deadline\":\"NOT_FOUND\",\"duration\":\"NOT_FOUND\",\"requirements_must\":\"시큐어 코딩 준수 및 웹 취약점 제거; 개인정보보호 정책 및 국정원 정보보안 관리실태 평가지표 준수; 소스코드 보안성 확보(표준코딩 스타일, 자체진단 및 제거방안)\",\"eval_items\":\"NOT_FOUND\",\"price_eval\":\"NOT_FOUND\",\"eligibility\":\"NOT_FOUND\",\"process_improvement\":\"가등록 프로세스 내 세부 프로세스 추가 및 오류 수정; 최초 가등록 단계에서 공공누리 유형 일괄 입력/수정 기능 추가; 가등록 업로드 후 수정 시 일부 해당 건의 자료 수정 기능 추가\",\"search_function\":\"검색 시 검색어와 무관한 검색 결과 도출 현상 개선; 자료검색 결과값의 아카이브 자료 번호순 정렬 기능 추가; 고급검색 관련 오류(기증자 선택 후 미출력 등) 수정; 검색 항목 화면\n",
      "dump is None? False\n",
      "top keys: ['id', 'created_at', 'error', 'incomplete_details', 'instructions', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'temperature', 'tool_choice', 'tools', 'top_p', 'background', 'completed_at', 'conversation', 'max_output_tokens', 'max_tool_calls', 'previous_response_id', 'prompt', 'prompt_cache_key', 'prompt_cache_retention', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'text', 'top_logprobs', 'truncation']\n",
      "status: completed\n",
      "usage.output_tokens: 556\n",
      "output item types: ['reasoning', 'message']\n"
     ]
    }
   ],
   "source": [
    "DEBUG = True  # 필요할 때만 True\n",
    "\n",
    "if DEBUG:\n",
    "    print(\"last_debug:\", getattr(rag.generator, \"last_debug\", None))\n",
    "\n",
    "    raw = getattr(rag.generator, \"last_raw_text\", \"\") or \"\"\n",
    "    print(\"raw_text_len:\", len(raw.strip()))\n",
    "    print(\"raw_text_preview:\\n\", raw[:600])\n",
    "\n",
    "    d = getattr(rag.generator, \"last_resp_dump\", None)\n",
    "    print(\"dump is None?\", d is None)\n",
    "    if isinstance(d, dict):\n",
    "        # responses API는 output_text가 별도 필드로 있을 수 있음(덤프엔 없을 때도 있음)\n",
    "        print(\"top keys:\", list(d.keys())[:30])\n",
    "        print(\"status:\", d.get(\"status\"))\n",
    "        usage = d.get(\"usage\") or {}\n",
    "        print(\"usage.output_tokens:\", usage.get(\"output_tokens\"))\n",
    "        out = d.get(\"output\")\n",
    "        if isinstance(out, list):\n",
    "            print(\"output item types:\", [x.get(\"type\") for x in out if isinstance(x, dict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "632a9b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_map sentinel counts: {'n_keys': 21, 'n_not_found': 11, 'n_gen_fail': 0}\n"
     ]
    }
   ],
   "source": [
    "# (옵션) GEN_FAIL/NOT_FOUND 비율 빠르게 보기: 마지막 doc 1개 기준\n",
    "try:\n",
    "    last_row = doc_df.iloc[-1].to_dict()\n",
    "    pm = last_row.get(\"pred_map\")\n",
    "    print(\"pred_map sentinel counts:\", count_sentinels(pm))\n",
    "except Exception as e:\n",
    "    print(\"pred_map sentinel counts: skipped:\", repr(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeit-part3-team4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
