{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "310947b4",
   "metadata": {},
   "source": [
    "### 사전 준비 사항 \n",
    "\n",
    "#### (1) uv add (터미널)\n",
    "\n",
    "```bash\n",
    "uv add rank_bm25\n",
    "```\n",
    "\n",
    "#### (2) .env 파일 세팅\n",
    "```bash\n",
    "OPENAI_API_KEY = \"\"\n",
    "HF_TOKEN = \"\"\n",
    "```\n",
    "\n",
    "#### (3) pdf 파일 세팅\n",
    "pdf 파일 100개를 `data/raw/files` 에 위치합니다.  \n",
    "eval 파일(csv 2개, jsonl 1개)을 `data/raw/eval` 에 위치합니다.(*30개 파일 합친 버전)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d68e1fc",
   "metadata": {},
   "source": [
    "#### 실행 방법\n",
    "\n",
    "1. 처음 1회(커널 새로 시작): 처음부터 끝까지 순서대로 실행\n",
    "2. exp1 결과 저장 확인\n",
    "3. <실험 ID 변경> 셀의 exp_id 를 변경 후 새로운 실험 진행 (실험 결과 저장 확인 후 커널 재시작)  \n",
    "\\*커널 재시작하지 않는 경우, 실험 ID 변경 + 실험 진행 섹션 코드만 실행해도 됨.(OOM 발생 가능성이 있어 권장하지 않음.)\n",
    "4. 원하는 실험로 변경 및 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4365838c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/won/dev/00_codeit/0_mission/200_DL_RAG/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold_evidence_df: (630, 5)\n",
      "gold_fields_df: (630, 4)\n",
      "questions_df: (311, 5)\n",
      "n_docs: 100\n"
     ]
    }
   ],
   "source": [
    "import json, re, unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from preprocess.pp_basic import docs, BASE_DIR, EVAL_DIR, GOLD_EVIDENCE_CSV, GOLD_FIELDS_JSONL\n",
    "from preprocess.rag_experiment import (\n",
    "    CONFIG, ExperimentSpec, load_questions_df, make_components, RAGExperiment\n",
    ")\n",
    "\n",
    "load_dotenv(find_dotenv(), override=False)\n",
    "client = OpenAI()\n",
    "\n",
    "# embed 모델은 커널에서 1번만 로드(중요)\n",
    "embed_model = SentenceTransformer(\"nlpai-lab/KoE5\")\n",
    "\n",
    "# gold 로드\n",
    "gold_evidence_df = pd.read_csv(GOLD_EVIDENCE_CSV)\n",
    "\n",
    "def load_gold_fields_jsonl(path):\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                rows.append(json.loads(line))\n",
    "    out = []\n",
    "    for r in rows:\n",
    "        iid = r[\"instance_id\"]\n",
    "        doc_id = r.get(\"doc_id\", \"\")\n",
    "        fields = r.get(\"fields\", {}) or {}\n",
    "        for k, v in fields.items():\n",
    "            out.append({\"instance_id\": iid, \"doc_id\": doc_id, \"field\": k, \"gold\": v})\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "gold_fields_df = load_gold_fields_jsonl(GOLD_FIELDS_JSONL)\n",
    "\n",
    "questions_df = load_questions_df()\n",
    "\n",
    "print(\"gold_evidence_df:\", gold_evidence_df.shape)\n",
    "print(\"gold_fields_df:\", gold_fields_df.shape)\n",
    "print(\"questions_df:\", questions_df.shape)\n",
    "print(\"n_docs:\", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3ef239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval docs: 30\n"
     ]
    }
   ],
   "source": [
    "# 평가 문서 필터(커널당 1회)\n",
    "def name_key(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFC\", str(s)).strip()\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "gold_doc_key_set = set(name_key(x) for x in gold_fields_df[\"doc_id\"].astype(str).unique())\n",
    "EVAL_DOCS = [p for p in docs if name_key(p.name) in gold_doc_key_set]\n",
    "\n",
    "print(\"Eval docs:\", len(EVAL_DOCS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e29b9a",
   "metadata": {},
   "source": [
    "### 실험 ID 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "841fa683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running spec: ExperimentSpec(exp_id=21, chunker='C4', retriever='R2', generator='G1')\n",
      "RUN_DOCS: 30\n"
     ]
    }
   ],
   "source": [
    "RUN_EXP_ID = 21   # 1~18\n",
    "N_DOCS = 5       # 디버깅은 1~5 추천, 전체는 None 또는 아래 라인 변경\n",
    "\n",
    "# N개 문서 또는 전체 문서 테스트\n",
    "# RUN_DOCS = EVAL_DOCS[:N_DOCS]\n",
    "RUN_DOCS = EVAL_DOCS\n",
    "\n",
    "# exp table (18개)\n",
    "SPECS = {\n",
    "    1:  (\"C1\",\"R1\",\"G1\"),  2:  (\"C1\",\"R1\",\"G2\"),\n",
    "    3:  (\"C1\",\"R2\",\"G1\"),  4:  (\"C1\",\"R2\",\"G2\"),\n",
    "    5:  (\"C1\",\"R3\",\"G1\"),  6:  (\"C1\",\"R3\",\"G2\"),\n",
    "    7:  (\"C2\",\"R1\",\"G1\"),  8:  (\"C2\",\"R1\",\"G2\"),\n",
    "    9:  (\"C2\",\"R2\",\"G1\"),  10: (\"C2\",\"R2\",\"G2\"),\n",
    "    11: (\"C2\",\"R3\",\"G1\"),  12: (\"C2\",\"R3\",\"G2\"),\n",
    "    13: (\"C3\",\"R1\",\"G1\"),  14: (\"C3\",\"R1\",\"G2\"),\n",
    "    15: (\"C3\",\"R2\",\"G1\"),  16: (\"C3\",\"R2\",\"G2\"),\n",
    "    17: (\"C3\",\"R3\",\"G1\"),  18: (\"C3\",\"R3\",\"G2\"),\n",
    "    19: (\"C4\",\"R1\",\"G1\"),  20: (\"C4\",\"R1\",\"G2\"),\n",
    "    21: (\"C4\",\"R2\",\"G1\"),  22: (\"C4\",\"R2\",\"G2\"),\n",
    "    23: (\"C4\",\"R3\",\"G1\"),  24: (\"C4\",\"R3\",\"G2\"),\n",
    "}\n",
    "\n",
    "c, r, g = SPECS[RUN_EXP_ID]\n",
    "spec = ExperimentSpec(exp_id=RUN_EXP_ID, chunker=c, retriever=r, generator=g)\n",
    "print(\"Running spec:\", spec)\n",
    "print(\"RUN_DOCS:\", len(RUN_DOCS))\n",
    "\n",
    "# (선택) 실험 컨텍스트 cap 조정하고 싶은 경우 주석 해제 및 수정\n",
    "# CONFIG[\"max_context_chars\"] = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18568f09",
   "metadata": {},
   "source": [
    "### 디버깅 사전 설정(선택)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82d566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (옵션) sentinel 모니터링용\n",
    "SENT_NOT_FOUND = \"NOT_FOUND\"\n",
    "SENT_GEN_FAIL = \"GEN_FAIL\"\n",
    "\n",
    "def count_sentinels(pred_map: dict) -> dict:\n",
    "    if not isinstance(pred_map, dict):\n",
    "        return {\"n_keys\": 0, \"n_not_found\": 0, \"n_gen_fail\": 0}\n",
    "\n",
    "    vals = [str(v).strip() for v in pred_map.values()]\n",
    "    vals_l = [v.lower() for v in vals]\n",
    "\n",
    "    n_nf = sum(v in {\"not_found\", \"notfound\"} for v in vals_l)\n",
    "    n_gf = sum(v == \"gen_fail\" for v in vals_l)\n",
    "    return {\"n_keys\": len(vals), \"n_not_found\": n_nf, \"n_gen_fail\": n_gf}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d607284f",
   "metadata": {},
   "source": [
    "### 실험 수행 및 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "521e9f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exp 21 docs:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클났따\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exp 21 docs:   0%|          | 0/30 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m rows = []\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc_path \u001b[38;5;129;01min\u001b[39;00m tqdm(RUN_DOCS, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExp \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec.exp_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m docs\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     m = \u001b[43mrag\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_single_doc_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdoc_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgold_fields_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgold_fields_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgold_evidence_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgold_evidence_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43msim_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m80\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     m[\u001b[33m\"\u001b[39m\u001b[33mexp_id\u001b[39m\u001b[33m\"\u001b[39m] = spec.exp_id\n\u001b[32m     14\u001b[39m     m[\u001b[33m\"\u001b[39m\u001b[33mchunker\u001b[39m\u001b[33m\"\u001b[39m] = spec.chunker\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/00_codeit/0_mission/200_DL_RAG/notebooks/preprocess/rag_experiment.py:460\u001b[39m, in \u001b[36mRAGExperiment.run_single_doc_metrics\u001b[39m\u001b[34m(self, doc_path, gold_fields_df, gold_evidence_df, top_k, sim_threshold, warn_on_mismatch)\u001b[39m\n\u001b[32m    457\u001b[39m type_keys = [t \u001b[38;5;28;01mfor\u001b[39;00m t, _q \u001b[38;5;129;01min\u001b[39;00m queries]\n\u001b[32m    459\u001b[39m \u001b[38;5;66;03m# 2) chunk -> index -> retrieve\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m index = \u001b[38;5;28mself\u001b[39m.retriever.build_index(chunks)\n\u001b[32m    462\u001b[39m idxs = \u001b[38;5;28mself\u001b[39m.retriever.retrieve(index, q_texts, top_k=top_k)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/00_codeit/0_mission/200_DL_RAG/notebooks/preprocess/rag_experiment.py:206\u001b[39m, in \u001b[36mC4DoclingChunker.chunk\u001b[39m\u001b[34m(self, doc_path)\u001b[39m\n\u001b[32m    204\u001b[39m chunks = chunk_from_alldata(doc_path.name, size=CONFIG[\u001b[33m\"\u001b[39m\u001b[33mchunk_length\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mC1FixedChunker\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchunk_length\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/00_codeit/0_mission/200_DL_RAG/notebooks/preprocess/rag_experiment.py:175\u001b[39m, in \u001b[36mC1FixedChunker.chunk\u001b[39m\u001b[34m(self, doc_path)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, doc_path: Path) -> List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     text = clean_text(\u001b[43mextract_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    176\u001b[39m     s = \u001b[38;5;28mself\u001b[39m.size\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [text[i:i+s] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(text), s)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/00_codeit/0_mission/200_DL_RAG/notebooks/preprocess/pp_v5.py:390\u001b[39m, in \u001b[36mextract_text\u001b[39m\u001b[34m(pdf_path)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_text\u001b[39m(pdf_path: Path | \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_extract_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/00_codeit/0_mission/200_DL_RAG/notebooks/preprocess/pp_v5.py:85\u001b[39m, in \u001b[36m_extract_text\u001b[39m\u001b[34m(pdf_path)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pdfplumber.open(pdf_path) \u001b[38;5;28;01mas\u001b[39;00m pdf:\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pdf.pages:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m         texts.append(\u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(texts)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/00_codeit/0_mission/200_DL_RAG/.venv/lib/python3.11/site-packages/pdfplumber/page.py:530\u001b[39m, in \u001b[36mPage.extract_text\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_textmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtuplify_list_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.as_string\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/00_codeit/0_mission/200_DL_RAG/.venv/lib/python3.11/site-packages/pdfplumber/page.py:507\u001b[39m, in \u001b[36mPage._get_textmap\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    505\u001b[39m     defaults.update({\u001b[33m\"\u001b[39m\u001b[33mlayout_height\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.height})\n\u001b[32m    506\u001b[39m full_kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] = {**defaults, **kwargs}\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m utils.chars_to_textmap(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchars\u001b[49m, **full_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/00_codeit/0_mission/200_DL_RAG/.venv/lib/python3.11/site-packages/pdfplumber/container.py:52\u001b[39m, in \u001b[36mContainer.chars\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchars\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> T_obj_list:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobjects\u001b[49m.get(\u001b[33m\"\u001b[39m\u001b[33mchar\u001b[39m\u001b[33m\"\u001b[39m, [])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/00_codeit/0_mission/200_DL_RAG/.venv/lib/python3.11/site-packages/pdfplumber/page.py:346\u001b[39m, in \u001b[36mPage.objects\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_objects\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._objects\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m \u001b[38;5;28mself\u001b[39m._objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._objects\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/00_codeit/0_mission/200_DL_RAG/.venv/lib/python3.11/site-packages/pdfplumber/page.py:443\u001b[39m, in \u001b[36mPage.parse_objects\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_objects\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list]:\n\u001b[32m    442\u001b[39m     objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] = {}\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_layout_objects(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayout\u001b[49m._objs):\n\u001b[32m    444\u001b[39m         kind = obj[\u001b[33m\"\u001b[39m\u001b[33mobject_type\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    445\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m kind \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33manno\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/00_codeit/0_mission/200_DL_RAG/.venv/lib/python3.11/site-packages/pdfplumber/page.py:266\u001b[39m, in \u001b[36mPage.layout\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    264\u001b[39m interpreter = PDFPageInterpreter(\u001b[38;5;28mself\u001b[39m.pdf.rsrcmgr, device)\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[43minterpreter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpage_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PdfminerException(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/00_codeit/0_mission/200_DL_RAG/.venv/lib/python3.11/site-packages/pdfminer/pdfinterp.py:1334\u001b[39m, in \u001b[36mPDFPageInterpreter.process_page\u001b[39m\u001b[34m(self, page)\u001b[39m\n\u001b[32m   1332\u001b[39m     ctm = (\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, -x0, -y0)\n\u001b[32m   1333\u001b[39m \u001b[38;5;28mself\u001b[39m.device.begin_page(page, ctm)\n\u001b[32m-> \u001b[39m\u001b[32m1334\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrender_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mctm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[38;5;28mself\u001b[39m.device.end_page(page)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/00_codeit/0_mission/200_DL_RAG/.venv/lib/python3.11/site-packages/pdfminer/pdfinterp.py:1355\u001b[39m, in \u001b[36mPDFPageInterpreter.render_contents\u001b[39m\u001b[34m(self, resources, streams, ctm)\u001b[39m\n\u001b[32m   1353\u001b[39m \u001b[38;5;28mself\u001b[39m.init_resources(resources)\n\u001b[32m   1354\u001b[39m \u001b[38;5;28mself\u001b[39m.init_state(ctm)\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstreams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/00_codeit/0_mission/200_DL_RAG/.venv/lib/python3.11/site-packages/pdfminer/pdfinterp.py:1389\u001b[39m, in \u001b[36mPDFPageInterpreter.execute\u001b[39m\u001b[34m(self, streams)\u001b[39m\n\u001b[32m   1387\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1388\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m         (_, obj) = \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnextobject\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1390\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m PSEOF:\n\u001b[32m   1391\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/00_codeit/0_mission/200_DL_RAG/.venv/lib/python3.11/site-packages/pdfminer/psparser.py:596\u001b[39m, in \u001b[36mPSStackParser.nextobject\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    588\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Yields a list of objects.\u001b[39;00m\n\u001b[32m    589\u001b[39m \n\u001b[32m    590\u001b[39m \u001b[33;03mArrays and dictionaries are represented as Python lists and\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    593\u001b[39m \u001b[33;03m:return: keywords, literals, strings, numbers, arrays and dictionaries.\u001b[39;00m\n\u001b[32m    594\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.results:\n\u001b[32m--> \u001b[39m\u001b[32m596\u001b[39m     (pos, token) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnexttoken\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    597\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, PSLiteral)):\n\u001b[32m    598\u001b[39m         \u001b[38;5;66;03m# normal token\u001b[39;00m\n\u001b[32m    599\u001b[39m         \u001b[38;5;28mself\u001b[39m.push((pos, token))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/00_codeit/0_mission/200_DL_RAG/.venv/lib/python3.11/site-packages/pdfminer/psparser.py:519\u001b[39m, in \u001b[36mPSBaseParser.nexttoken\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    517\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    518\u001b[39m token = \u001b[38;5;28mself\u001b[39m._tokens.pop(\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnexttoken: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    520\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m token\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "chunker, retriever, generator = make_components(spec, embed_model=embed_model, client=client)\n",
    "rag = RAGExperiment(chunker=chunker, retriever=retriever, generator=generator, questions_df=questions_df)\n",
    "\n",
    "rows = []\n",
    "for doc_path in tqdm(RUN_DOCS, desc=f\"Exp {spec.exp_id} docs\"):\n",
    "    m = rag.run_single_doc_metrics(\n",
    "        doc_path,\n",
    "        gold_fields_df=gold_fields_df,\n",
    "        gold_evidence_df=gold_evidence_df,\n",
    "        top_k=CONFIG[\"top_k\"],\n",
    "        sim_threshold=80,\n",
    "    )\n",
    "    m[\"exp_id\"] = spec.exp_id\n",
    "    m[\"chunker\"] = spec.chunker\n",
    "    m[\"retriever\"] = spec.retriever\n",
    "    m[\"generator\"] = spec.generator\n",
    "    rows.append(m)\n",
    "\n",
    "doc_df = pd.DataFrame(rows)\n",
    "\n",
    "# exp-level average\n",
    "avg = doc_df[[\"ret_recall\",\"ret_mrr\",\"gen_fill\",\"gen_match\",\"gen_sim\"]].mean(numeric_only=True)\n",
    "exp_df = pd.DataFrame([{\n",
    "    \"exp_id\": spec.exp_id,\n",
    "    \"chunk\": spec.chunker,\n",
    "    \"retriever\": spec.retriever,\n",
    "    \"model\": spec.generator,\n",
    "    \"n_docs\": len(doc_df),\n",
    "    **{k: float(avg[k]) for k in avg.index},\n",
    "}])\n",
    "\n",
    "display(exp_df.round(4))\n",
    "\n",
    "out_dir = BASE_DIR / \"outputs\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "exp_out = out_dir / f\"exp{spec.exp_id:02d}_explevel.csv\"\n",
    "exp_df.to_csv(exp_out, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved:\", exp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b1d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pred_maps: 30 -> /Users/won/dev/00_codeit/0_mission/200_DL_RAG/outputs/exp21_pred_maps\n"
     ]
    }
   ],
   "source": [
    "# 문서별 pred_map 저장 (옵션)\n",
    "pred_dir = out_dir / f\"exp{spec.exp_id:02d}_pred_maps\"\n",
    "pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "saved = 0\n",
    "for _, row in doc_df.iterrows():\n",
    "    doc_id = str(row[\"doc_id\"])\n",
    "    pred_map = row.get(\"pred_map\", None)\n",
    "    if isinstance(pred_map, dict):\n",
    "        # 파일명 안전화\n",
    "        safe = re.sub(r\"[\\\\/:*?\\\"<>|]\", \"_\", doc_id)\n",
    "        path = pred_dir / f\"{safe}.json\"\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(pred_map, f, ensure_ascii=False, indent=2)\n",
    "        saved += 1\n",
    "\n",
    "print(\"Saved pred_maps:\", saved, \"->\", pred_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0d2889",
   "metadata": {},
   "source": [
    "### 디버깅(선택)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce56f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_debug: {'model': 'gpt-5-mini', 'n_questions': 21, 'context_len': 4000, 'max_context_chars': 4000, 'prompt_len': 5856, 'response_status': 'completed', 'output_tokens': 561, 'output_text_repr': '\\'{\"project_name\":\"국립민속박물관 민속아카이브 자료관리시스템 기능개선\",\"agency\":\"국립민속박물관 유물과학과\",\"purpose\":\"민속아카이브 자료관리시스템 업무 프로세스 강화 및 상태 모니터링·자료관리 기능 강화, 사용자 편의성 개선\",\"budget\":\"금 77,000,000 원 (금칠천칠백만원, 부가세 포함)\",\"contract_type\\'', 'exception': None, 'parse_error': None}\n",
      "raw_text_len: 1196\n",
      "raw_text_preview:\n",
      " {\"project_name\":\"국립민속박물관 민속아카이브 자료관리시스템 기능개선\",\"agency\":\"국립민속박물관 유물과학과\",\"purpose\":\"민속아카이브 자료관리시스템 업무 프로세스 강화 및 상태 모니터링·자료관리 기능 강화, 사용자 편의성 개선\",\"budget\":\"금 77,000,000 원 (금칠천칠백만원, 부가세 포함)\",\"contract_type\":\"제한경쟁입찰 (협상에 의한 계약)\",\"deadline\":\"NOT_FOUND\",\"duration\":\"계약 후 2024.12.20.(금)\",\"requirements_must\":\"서버 스크립트 파일 업로드 제한; 디스팅 방지; 홈페이지 절대경로 및 내부시스템 정보 노출 방지; 홈페이지 관리자 페이지 접근 통제; 업체 소유 전자기록 저장매체 완전 삭제 후 반출; 하자보수 지원 방안 및 하자담보책임기간 12개월\",\"eval_items\":\"기술평가 (90%) / 가격평가 (10%)\",\"price_eval\":\"가격평가 10% (평가방식에 가격평가 포함)\",\"eligibility\":\"소프트웨어진흥법에 의한 소프트웨어사업자(컴퓨터 관련 서비스사업, 업종코드:1468)로 등록된 업체; 「국가를 당사자로 하는 계약에 관한\n",
      "dump is None? False\n",
      "top keys: ['id', 'created_at', 'error', 'incomplete_details', 'instructions', 'metadata', 'model', 'object', 'output', 'parallel_tool_calls', 'temperature', 'tool_choice', 'tools', 'top_p', 'background', 'completed_at', 'conversation', 'max_output_tokens', 'max_tool_calls', 'previous_response_id', 'prompt', 'prompt_cache_key', 'prompt_cache_retention', 'reasoning', 'safety_identifier', 'service_tier', 'status', 'text', 'top_logprobs', 'truncation']\n",
      "status: completed\n",
      "usage.output_tokens: 561\n",
      "output item types: ['reasoning', 'message']\n"
     ]
    }
   ],
   "source": [
    "DEBUG = True  # 필요할 때만 True\n",
    "\n",
    "if DEBUG:\n",
    "    print(\"last_debug:\", getattr(rag.generator, \"last_debug\", None))\n",
    "\n",
    "    raw = getattr(rag.generator, \"last_raw_text\", \"\") or \"\"\n",
    "    print(\"raw_text_len:\", len(raw.strip()))\n",
    "    print(\"raw_text_preview:\\n\", raw[:600])\n",
    "\n",
    "    d = getattr(rag.generator, \"last_resp_dump\", None)\n",
    "    print(\"dump is None?\", d is None)\n",
    "    if isinstance(d, dict):\n",
    "        # responses API는 output_text가 별도 필드로 있을 수 있음(덤프엔 없을 때도 있음)\n",
    "        print(\"top keys:\", list(d.keys())[:30])\n",
    "        print(\"status:\", d.get(\"status\"))\n",
    "        usage = d.get(\"usage\") or {}\n",
    "        print(\"usage.output_tokens:\", usage.get(\"output_tokens\"))\n",
    "        out = d.get(\"output\")\n",
    "        if isinstance(out, list):\n",
    "            print(\"output item types:\", [x.get(\"type\") for x in out if isinstance(x, dict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632a9b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_map sentinel counts: {'n_keys': 21, 'n_not_found': 5, 'n_gen_fail': 0}\n"
     ]
    }
   ],
   "source": [
    "# (옵션) GEN_FAIL/NOT_FOUND 비율 빠르게 보기: 마지막 doc 1개 기준\n",
    "try:\n",
    "    last_row = doc_df.iloc[-1].to_dict()\n",
    "    pm = last_row.get(\"pred_map\")\n",
    "    print(\"pred_map sentinel counts:\", count_sentinels(pm))\n",
    "except Exception as e:\n",
    "    print(\"pred_map sentinel counts: skipped:\", repr(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "200_DL_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
