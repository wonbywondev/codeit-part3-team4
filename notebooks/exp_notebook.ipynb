{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "310947b4",
   "metadata": {},
   "source": [
    "### 사전 준비 사항 \n",
    "\n",
    "#### (1) uv add (터미널)\n",
    "\n",
    "```bash\n",
    "uv add rank_bm25\n",
    "```\n",
    "\n",
    "#### (2) .env 파일 세팅\n",
    "```bash\n",
    "OPENAI_API_KEY = \"\"\n",
    "HF_TOKEN = \"\"\n",
    "```\n",
    "\n",
    "#### (3) pdf 파일 세팅\n",
    "pdf 파일 100개를 `data/raw/files` 에 위치합니다.  \n",
    "eval 파일(csv 2개, jsonl 1개)을 `data/raw/eval` 에 위치합니다.(*30개 파일 합친 버전)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d68e1fc",
   "metadata": {},
   "source": [
    "#### 실행 방법\n",
    "\n",
    "1. 처음 1회(커널 새로 시작): 처음부터 끝까지 순서대로 실행\n",
    "2. exp1 결과 저장 확인\n",
    "3. <실험 ID 변경> 셀의 exp_id 를 변경 후 새로운 실험 진행 (실험 결과 저장 확인 후 커널 재시작)  \n",
    "\\*커널 재시작하지 않는 경우, 실험 ID 변경 + 실험 진행 섹션 코드만 실행해도 됨.(OOM 발생 가능성이 있어 권장하지 않음.)\n",
    "4. 원하는 실험로 변경 및 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4365838c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\github\\codeit-part3-team4\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading weights: 100%|██████████| 391/391 [00:00<00:00, 886.27it/s, Materializing param=pooler.dense.weight]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold_evidence_df: (630, 5)\n",
      "gold_fields_df: (630, 4)\n",
      "questions_df: (311, 5)\n",
      "n_docs: 100\n"
     ]
    }
   ],
   "source": [
    "# 공통 준비(커널 시작마다 1회)\n",
    "\n",
    "import json, re, unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from preprocess.pp_basic import docs, BASE_DIR, EVAL_DIR, GOLD_EVIDENCE_CSV, GOLD_FIELDS_JSONL\n",
    "from preprocess.rag_experiment import (\n",
    "    CONFIG, ExperimentSpec, load_questions_df, make_components, RAGExperiment\n",
    ")\n",
    "\n",
    "load_dotenv(find_dotenv(), override=False)\n",
    "client = OpenAI()\n",
    "\n",
    "# embed 모델은 커널에서 1번만 로드(중요)\n",
    "embed_model = SentenceTransformer(\"nlpai-lab/KoE5\")\n",
    "\n",
    "# gold 로드 (baseline 함수 재사용하던 것과 동일하게)\n",
    "gold_evidence_df = pd.read_csv(GOLD_EVIDENCE_CSV)\n",
    "\n",
    "def load_gold_fields_jsonl(path):\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                rows.append(json.loads(line))\n",
    "    out = []\n",
    "    for r in rows:\n",
    "        iid = r[\"instance_id\"]\n",
    "        doc_id = r.get(\"doc_id\", \"\")\n",
    "        fields = r.get(\"fields\", {}) or {}\n",
    "        for k, v in fields.items():\n",
    "            out.append({\"instance_id\": iid, \"doc_id\": doc_id, \"field\": k, \"gold\": v})\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "gold_fields_df = load_gold_fields_jsonl(GOLD_FIELDS_JSONL)\n",
    "\n",
    "questions_df = load_questions_df()\n",
    "\n",
    "print(\"gold_evidence_df:\", gold_evidence_df.shape)\n",
    "print(\"gold_fields_df:\", gold_fields_df.shape)\n",
    "print(\"questions_df:\", questions_df.shape)\n",
    "print(\"n_docs:\", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3ef239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval docs: 30\n"
     ]
    }
   ],
   "source": [
    "# 평가 문서 필터(커널당 1회)\n",
    "def name_key(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFC\", s).strip()\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "gold_doc_key_set = set(name_key(x) for x in gold_fields_df[\"doc_id\"].astype(str).unique())\n",
    "EVAL_DOCS = [p for p in docs if name_key(p.name) in gold_doc_key_set]\n",
    "\n",
    "print(\"Eval docs:\", len(EVAL_DOCS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e29b9a",
   "metadata": {},
   "source": [
    "### 실험 ID 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "841fa683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running spec: ExperimentSpec(exp_id=1, chunker='C1', retriever='R1', generator='G1')\n",
      "RUN_DOCS: 5\n"
     ]
    }
   ],
   "source": [
    "# 이번 실행 실험 1개만 선택 (여기만 바꿔가며 실행)\n",
    "\n",
    "RUN_EXP_ID = 1  # 1~18\n",
    "N_DOCS = 5\n",
    "\n",
    "# N개 문서 또는 전체 문서 테스트(주석 처리)\n",
    "RUN_DOCS = EVAL_DOCS[:N_DOCS] \n",
    "# RUN_DOCS = EVAL_DOCS\n",
    "\n",
    "# exp table (18개)\n",
    "SPECS = {\n",
    "    1:  (\"C1\",\"R1\",\"G1\"),  2:  (\"C1\",\"R1\",\"G2\"),\n",
    "    3:  (\"C1\",\"R2\",\"G1\"),  4:  (\"C1\",\"R2\",\"G2\"),\n",
    "    5:  (\"C1\",\"R3\",\"G1\"),  6:  (\"C1\",\"R3\",\"G2\"),\n",
    "    7:  (\"C2\",\"R1\",\"G1\"),  8:  (\"C2\",\"R1\",\"G2\"),\n",
    "    9:  (\"C2\",\"R2\",\"G1\"),  10: (\"C2\",\"R2\",\"G2\"),\n",
    "    11: (\"C2\",\"R3\",\"G1\"),  12: (\"C2\",\"R3\",\"G2\"),\n",
    "    13: (\"C3\",\"R1\",\"G1\"),  14: (\"C3\",\"R1\",\"G2\"),\n",
    "    15: (\"C3\",\"R2\",\"G1\"),  16: (\"C3\",\"R2\",\"G2\"),\n",
    "    17: (\"C3\",\"R3\",\"G1\"),  18: (\"C3\",\"R3\",\"G2\"),\n",
    "}\n",
    "\n",
    "c, r, g = SPECS[RUN_EXP_ID]\n",
    "spec = ExperimentSpec(exp_id=RUN_EXP_ID, chunker=c, retriever=r, generator=g)\n",
    "print(\"Running spec:\", spec)\n",
    "print(\"RUN_DOCS:\", len(RUN_DOCS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d607284f",
   "metadata": {},
   "source": [
    "### 실험 수행 및 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "521e9f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exp 1 docs:  40%|████      | 2/5 [01:47<02:33, 51.24s/it]d:\\dev\\github\\codeit-part3-team4\\notebooks\\preprocess\\rag_experiment.py:398: RuntimeWarning: Mean of empty slice\n",
      "  \"ret_recall\": float(np.nanmean([x[\"recall\"] for x in r_list])),\n",
      "d:\\dev\\github\\codeit-part3-team4\\notebooks\\preprocess\\rag_experiment.py:399: RuntimeWarning: Mean of empty slice\n",
      "  \"ret_mrr\": float(np.nanmean([x[\"mrr\"] for x in r_list])),\n",
      "d:\\dev\\github\\codeit-part3-team4\\notebooks\\preprocess\\rag_experiment.py:402: RuntimeWarning: Mean of empty slice\n",
      "  \"gen_match\": float(np.nanmean([x[\"match\"] for x in g_list])),\n",
      "d:\\dev\\github\\codeit-part3-team4\\notebooks\\preprocess\\rag_experiment.py:403: RuntimeWarning: Mean of empty slice\n",
      "  \"gen_sim\": float(np.nanmean([x[\"sim\"] for x in g_list])),\n",
      "Exp 1 docs: 100%|██████████| 5/5 [04:00<00:00, 48.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_id</th>\n",
       "      <th>chunk</th>\n",
       "      <th>retriever</th>\n",
       "      <th>model</th>\n",
       "      <th>n_docs</th>\n",
       "      <th>ret_recall</th>\n",
       "      <th>ret_mrr</th>\n",
       "      <th>gen_fill</th>\n",
       "      <th>gen_match</th>\n",
       "      <th>gen_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C1</td>\n",
       "      <td>R1</td>\n",
       "      <td>G1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7738</td>\n",
       "      <td>0.3604</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>3.9452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exp_id chunk retriever model  n_docs  ret_recall  ret_mrr  gen_fill  \\\n",
       "0       1    C1        R1    G1       5      0.7738   0.3604       1.0   \n",
       "\n",
       "   gen_match  gen_sim  \n",
       "0     0.0369   3.9452  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: d:\\dev\\github\\codeit-part3-team4\\outputs\\exp01_doclevel.csv\n",
      "Saved: d:\\dev\\github\\codeit-part3-team4\\outputs\\exp01_explevel.csv\n"
     ]
    }
   ],
   "source": [
    "# 실행 + 저장 (매 exp_id마다 1번 실행)\n",
    "\n",
    "chunker, retriever, generator = make_components(spec, embed_model=embed_model, client=client)\n",
    "rag = RAGExperiment(chunker=chunker, retriever=retriever, generator=generator, questions_df=questions_df)\n",
    "\n",
    "rows = []\n",
    "for doc_path in tqdm(RUN_DOCS, desc=f\"Exp {spec.exp_id} docs\"):\n",
    "    m = rag.run_single_doc_metrics(\n",
    "        doc_path,\n",
    "        gold_fields_df=gold_fields_df,\n",
    "        gold_evidence_df=gold_evidence_df,\n",
    "        top_k=CONFIG[\"top_k\"],\n",
    "        sim_threshold=80,\n",
    "    )\n",
    "    m[\"exp_id\"] = spec.exp_id\n",
    "    m[\"chunker\"] = spec.chunker\n",
    "    m[\"retriever\"] = spec.retriever\n",
    "    m[\"generator\"] = spec.generator\n",
    "    rows.append(m)\n",
    "\n",
    "doc_df = pd.DataFrame(rows)\n",
    "\n",
    "# exp-level average\n",
    "avg = doc_df[[\"ret_recall\",\"ret_mrr\",\"gen_fill\",\"gen_match\",\"gen_sim\"]].mean(numeric_only=True)\n",
    "exp_df = pd.DataFrame([{\n",
    "    \"exp_id\": spec.exp_id,\n",
    "    \"chunk\": spec.chunker,\n",
    "    \"retriever\": spec.retriever,\n",
    "    \"model\": spec.generator,\n",
    "    \"n_docs\": len(doc_df),\n",
    "    **{k: float(avg[k]) for k in avg.index},\n",
    "}])\n",
    "\n",
    "display(exp_df.round(4))\n",
    "\n",
    "out_dir = BASE_DIR / \"outputs\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "doc_out = out_dir / f\"exp{spec.exp_id:02d}_doclevel.csv\"\n",
    "exp_out = out_dir / f\"exp{spec.exp_id:02d}_explevel.csv\"\n",
    "\n",
    "doc_df.to_csv(doc_out, index=False, encoding=\"utf-8-sig\")\n",
    "exp_df.to_csv(exp_out, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Saved:\", doc_out)\n",
    "print(\"Saved:\", exp_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeit-part3-team4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
