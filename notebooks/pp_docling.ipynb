{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "655a6107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/won/dev/00_codeit/0_mission/200_DL_RAG/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import preprocess.pp_v4 as pp\n",
    "from preprocess.pp_basic import BASE_DIR, RAW_DIR, DATA_DIR, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52aea8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95f8c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = str(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437158c4",
   "metadata": {},
   "source": [
    "## 표 데이터 추출 이쁘게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55233b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import docling.utils.model_downloader\n",
    "# docling.utils.model_downloader.download_models()\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import EasyOcrOptions, PdfPipelineOptions, TableFormerMode\n",
    "\n",
    "pipeline_options = PdfPipelineOptions(do_table_structure=True)\n",
    "pipeline_options.table_structure_options.mode = TableFormerMode.ACCURATE  # use more accurate TableFormer model\n",
    "pipeline_options.table_structure_options.do_cell_matching = True  # uses text cells predicted from table structure model\n",
    "\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "doc = doc_converter.convert(PDF_PATH).document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2afe7839",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = dict()\n",
    "for tuple_ in list(doc):\n",
    "    new_dict[tuple_[0]] = tuple_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b59fe6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n",
      "Usage of TableItem.export_to_markdown() without `doc` argument is deprecated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Part 1: 문서 기본 정보 및 통계\n",
      "================================================================================\n",
      "\n",
      "=== new_dict 구조 ===\n",
      "schema_name: str\n",
      "version: str\n",
      "name: str\n",
      "origin: DocumentOrigin\n",
      "furniture: GroupItem\n",
      "body: GroupItem\n",
      "groups: list (138 items)\n",
      "texts: list (1546 items)\n",
      "pictures: list (9 items)\n",
      "tables: list (172 items)\n",
      "key_value_items: list (0 items)\n",
      "form_items: list (0 items)\n",
      "pages: dict (131 items)\n",
      "\n",
      "=== 문서 메타데이터 ===\n",
      "파일명: (사)벤처기업협회_2024년 벤처확인종합관리시스템 기능 고도화 용역사업 \n",
      "스키마: DoclingDocument\n",
      "버전: 1.9.0\n",
      "총 페이지: 131\n",
      "총 텍스트 요소: 1546\n",
      "총 테이블: 172\n",
      "총 이미지: 9\n",
      "총 그룹: 138\n",
      "\n",
      "=== 텍스트 라벨 분포 ===\n",
      "text: 757\n",
      "list_item: 485\n",
      "section_header: 150\n",
      "page_footer: 129\n",
      "page_header: 11\n",
      "caption: 5\n",
      "checkbox_unselected: 5\n",
      "footnote: 4\n",
      "\n",
      "================================================================================\n",
      "Part 2: 계층 구조 추론\n",
      "================================================================================\n",
      "\n",
      "총 섹션: 150\n",
      "\n",
      "=== 계층 통계 ===\n",
      "Level 1: 9개\n",
      "Level 2: 28개\n",
      "Level 3: 79개\n",
      "Level 4: 34개\n",
      "\n",
      "=== 계층 구조 샘플 (첫 15개) ===\n",
      "~     L3: 2024 2024 2024 2024 2024 2024 년 년 년 년 년 년 ｢ ｢ ｢ ｢ ｢ ｢ 벤처확인종합\n",
      "~ L1: 제안요청서 제안요청서 제안요청서 제안요청서 제안요청서 제안요청서 제안요청서 제안요청서 제안요청서 제안요청서 \n",
      "~     L3: 목 차\n",
      "✓ L1: Ⅰ . 추진개요\n",
      "✓   L2: 1 추진배경 및 방향\n",
      "~       L4: 행정기관 및 공공기관 정보시스템 구축․운영 지침\n",
      "~       L4: 제18조(평가배점)\n",
      "✓ L1: Ⅱ . 사업 추진방안\n",
      "✓   L2: 1 추진목표\n",
      "~ L1: 추진 목표\n",
      "✓   L2: 2 추진체계 및 역할\n",
      "✓     L3: □ 추진체계\n",
      "✓     L3: □ 추진역할\n",
      "~       L4: 중소벤처기업부\n",
      "~       L4: 벤처기업확인기관\n",
      "\n",
      "================================================================================\n",
      "Part 3: 계층적 문서 구조\n",
      "================================================================================\n",
      "총 최상위 항목: 146\n",
      "섹션 수: 146\n",
      "\n",
      "================================================================================\n",
      "Part 4: RAG 검색 인덱스 생성 (노이즈 제거)\n",
      "================================================================================\n",
      "원본 인덱스: 2796개\n",
      "정제 후 인덱스: 1386개\n",
      "제거율: 50.4%\n",
      "\n",
      "================================================================================\n",
      "Part 5: 파일 저장\n",
      "================================================================================\n",
      "✓ document_hierarchical.json 저장 완료\n",
      "✓ document_hierarchy.json 저장 완료\n",
      "✓ search_index_cleaned.json 저장 완료\n",
      "✓ document_metadata.json 저장 완료\n",
      "\n",
      "================================================================================\n",
      "완료! 생성된 파일:\n",
      "  - document_hierarchical.json (계층 구조)\n",
      "  - document_hierarchy.json (계층 정보)\n",
      "  - search_index_cleaned.json (정제된 RAG 인덱스)\n",
      "  - document_metadata.json (통합 메타데이터)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# =============================================================================\n",
    "# 헬퍼 함수들\n",
    "# =============================================================================\n",
    "\n",
    "def resolve_ref(doc, ref_string):\n",
    "    \"\"\"RefItem을 실제 객체로 변환\"\"\"\n",
    "    if not ref_string or not ref_string.startswith('#/'):\n",
    "        return None\n",
    "    \n",
    "    parts = ref_string.split('/')\n",
    "    if len(parts) < 3:\n",
    "        return None\n",
    "    \n",
    "    collection = parts[1]\n",
    "    idx = int(parts[2])\n",
    "    \n",
    "    try:\n",
    "        if collection == 'texts':\n",
    "            return doc.texts[idx]\n",
    "        elif collection == 'groups':\n",
    "            return doc.groups[idx]\n",
    "        elif collection == 'tables':\n",
    "            return doc.tables[idx]\n",
    "        elif collection == 'pictures':\n",
    "            return doc.pictures[idx]\n",
    "    except (IndexError, AttributeError):\n",
    "        return None\n",
    "    \n",
    "    return None\n",
    "\n",
    "def safe_export_markdown(table):\n",
    "    \"\"\"테이블을 마크다운으로 안전하게 변환\"\"\"\n",
    "    try:\n",
    "        if hasattr(table, 'export_to_markdown'):\n",
    "            result = table.export_to_markdown()\n",
    "            if isinstance(result, str):\n",
    "                return result\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: 테이블 마크다운 변환 실패 - {e}\")\n",
    "    return None\n",
    "\n",
    "# =============================================================================\n",
    "# 노이즈 제거 클래스\n",
    "# =============================================================================\n",
    "\n",
    "class SearchIndexCleaner:\n",
    "    \"\"\"검색 인덱스 노이즈 제거\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.exclude_labels = [\n",
    "            'page_header',\n",
    "            'page_footer', \n",
    "            'checkbox_unselected',\n",
    "            'checkbox_selected'\n",
    "        ]\n",
    "        \n",
    "        self.noise_patterns = [\n",
    "            r'^\\d+\\.$',                    # \"1.\", \"2.\"\n",
    "            r'^\\d+$',                       # \"1\", \"2\"\n",
    "            r'^[A-Za-z]$',                  # 단일 문자\n",
    "            r'^[□○●◆◇▪▫⚬◦*-]+$',         # 기호만\n",
    "            r'^M[+-]?\\d*$',                 # \"M\", \"M-1\"\n",
    "            r'^제\\s*\\d+\\s*조$',             # \"제1조\"\n",
    "            r'^[가-힣]{1,2}$',               # 1-2자 한글\n",
    "        ]\n",
    "        \n",
    "        self.valid_short_texts = {\n",
    "            '목차', '서론', '결론', '요약', '개요',\n",
    "            '배경', '목적', '방법', '결과', '고찰'\n",
    "        }\n",
    "    \n",
    "    def is_noise(self, text, label=None):\n",
    "        \"\"\"노이즈 여부 판단\"\"\"\n",
    "        text = text.strip()\n",
    "        \n",
    "        # 화이트리스트\n",
    "        if text in self.valid_short_texts:\n",
    "            return False\n",
    "        \n",
    "        # 섹션 헤더/캡션은 관대\n",
    "        if label in ['section_header', 'caption'] and len(text) >= 2:\n",
    "            return False\n",
    "        \n",
    "        # 제외 라벨\n",
    "        if label in self.exclude_labels:\n",
    "            return True\n",
    "        \n",
    "        # 길이 제한\n",
    "        if len(text) <= 2:\n",
    "            return True\n",
    "        \n",
    "        # 노이즈 패턴\n",
    "        for pattern in self.noise_patterns:\n",
    "            if re.match(pattern, text):\n",
    "                return True\n",
    "        \n",
    "        # 반복 문자\n",
    "        words = text.split()\n",
    "        if len(words) > 3:\n",
    "            word_counts = Counter(words)\n",
    "            if any(count >= 3 for count in word_counts.values()):\n",
    "                return True\n",
    "        \n",
    "        # 특수문자 비율\n",
    "        special_chars = sum(1 for c in text if not c.isalnum() and not c.isspace())\n",
    "        if len(text) > 0 and special_chars / len(text) > 0.5:\n",
    "            return True\n",
    "        \n",
    "        # 짧은 숫자만\n",
    "        if text.replace(' ', '').replace('.', '').replace(',', '').isdigit():\n",
    "            if len(text.replace(' ', '').replace('.', '').replace(',', '')) < 4:\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def normalize_text(self, text):\n",
    "        \"\"\"텍스트 정규화\"\"\"\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = re.sub(r'\\.{4,}', '...', text)\n",
    "        text = re.sub(r'·{3,}', '...', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    def clean_search_index(self, search_index):\n",
    "        \"\"\"검색 인덱스 정제\"\"\"\n",
    "        cleaned = []\n",
    "        \n",
    "        for item in search_index:\n",
    "            content = item['content']\n",
    "            label = item['metadata'].get('label')\n",
    "            \n",
    "            if self.is_noise(content, label):\n",
    "                continue\n",
    "            \n",
    "            content = self.normalize_text(content)\n",
    "            \n",
    "            if len(content.strip()) < 3 and label != 'section_header':\n",
    "                continue\n",
    "            \n",
    "            item['content'] = content\n",
    "            cleaned.append(item)\n",
    "        \n",
    "        return cleaned\n",
    "\n",
    "# =============================================================================\n",
    "# 계층 추론 클래스\n",
    "# =============================================================================\n",
    "\n",
    "class HierarchyDetector:\n",
    "    \"\"\"문서 계층 자동 추론\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.patterns = [\n",
    "            (r'^[ⅠⅡⅢⅣⅤⅥⅦⅧⅨⅩ]', 1, '로마숫자'),\n",
    "            (r'^제\\s*[0-9]+\\s*장', 1, '제N장'),\n",
    "            (r'^\\d+\\s+[가-힣A-Za-z]', 2, '숫자+공백'),\n",
    "            (r'^\\d+\\.\\s*[가-힣A-Za-z]', 2, '숫자.공백'),\n",
    "            (r'^\\d+\\.\\d+', 3, '숫자.숫자'),\n",
    "            (r'^[□○●◆◇▪▫]', 3, '박스기호'),\n",
    "            (r'^\\(\\d+\\)', 3, '(숫자)'),\n",
    "            (r'^\\d+\\)\\s', 4, '숫자)'),\n",
    "            (r'^[A-Z]\\.\\s', 4, '영대문자.'),\n",
    "            (r'^[a-z]\\.\\s', 5, '영소문자.'),\n",
    "        ]\n",
    "    \n",
    "    def detect_level_by_pattern(self, text):\n",
    "        \"\"\"패턴으로 레벨 추론\"\"\"\n",
    "        text = text.strip()\n",
    "        for pattern, level, name in self.patterns:\n",
    "            if re.match(pattern, text):\n",
    "                return level, name\n",
    "        return None, None\n",
    "    \n",
    "    def detect_level_by_bbox(self, header):\n",
    "        \"\"\"BBox 크기로 레벨 추론\"\"\"\n",
    "        if not header.prov:\n",
    "            return None\n",
    "        \n",
    "        height = header.prov[0].bbox.t - header.prov[0].bbox.b\n",
    "        \n",
    "        if height > 25:\n",
    "            return 1\n",
    "        elif height > 18:\n",
    "            return 2\n",
    "        elif height > 12:\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "    \n",
    "    def infer_hierarchy(self, section_headers):\n",
    "        \"\"\"섹션 헤더 목록에서 계층 추론\"\"\"\n",
    "        results = []\n",
    "        prev_level = 1\n",
    "        \n",
    "        for header in section_headers:\n",
    "            text = header.text.strip()\n",
    "            \n",
    "            pattern_level, pattern_name = self.detect_level_by_pattern(text)\n",
    "            bbox_level = self.detect_level_by_bbox(header)\n",
    "            \n",
    "            levels = []\n",
    "            weights = []\n",
    "            \n",
    "            if pattern_level:\n",
    "                levels.append(pattern_level)\n",
    "                weights.append(3)\n",
    "            \n",
    "            if bbox_level:\n",
    "                levels.append(bbox_level)\n",
    "                weights.append(2)\n",
    "            \n",
    "            if levels:\n",
    "                final_level = round(sum(l * w for l, w in zip(levels, weights)) / sum(weights))\n",
    "            else:\n",
    "                final_level = min(prev_level + 1, 5)\n",
    "            \n",
    "            confidence = 'high' if pattern_level else 'medium' if bbox_level else 'low'\n",
    "            \n",
    "            results.append({\n",
    "                'text': text,\n",
    "                'level': final_level,\n",
    "                'confidence': confidence,\n",
    "                'pattern': pattern_name,\n",
    "                'page': header.prov[0].page_no if header.prov else None\n",
    "            })\n",
    "            \n",
    "            prev_level = final_level\n",
    "        \n",
    "        return results\n",
    "\n",
    "# =============================================================================\n",
    "# Part 1: 문서 기본 정보\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Part 1: 문서 기본 정보 및 통계\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n=== new_dict 구조 ===\")\n",
    "for key, value in new_dict.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"{key}: dict ({len(value)} items)\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"{key}: list ({len(value)} items)\")\n",
    "    else:\n",
    "        print(f\"{key}: {type(value).__name__}\")\n",
    "\n",
    "print(\"\\n=== 문서 메타데이터 ===\")\n",
    "print(f\"파일명: {new_dict['name']}\")\n",
    "print(f\"스키마: {new_dict['schema_name']}\")\n",
    "print(f\"버전: {new_dict['version']}\")\n",
    "print(f\"총 페이지: {len(new_dict['pages'])}\")\n",
    "print(f\"총 텍스트 요소: {len(new_dict['texts'])}\")\n",
    "print(f\"총 테이블: {len(new_dict['tables'])}\")\n",
    "print(f\"총 이미지: {len(new_dict['pictures'])}\")\n",
    "print(f\"총 그룹: {len(new_dict['groups'])}\")\n",
    "\n",
    "# 텍스트 라벨 분석\n",
    "print(\"\\n=== 텍스트 라벨 분포 ===\")\n",
    "labels = [str(text.label) for text in new_dict['texts'] if hasattr(text, 'label')]\n",
    "label_counts = Counter(labels)\n",
    "\n",
    "for label, count in label_counts.most_common():\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Part 2: 계층 구조 추론\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Part 2: 계층 구조 추론\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "detector = HierarchyDetector()\n",
    "section_headers = [t for t in new_dict['texts'] if hasattr(t, 'label') and str(t.label) == 'section_header']\n",
    "hierarchy = detector.infer_hierarchy(section_headers)\n",
    "\n",
    "print(f\"\\n총 섹션: {len(hierarchy)}\")\n",
    "\n",
    "# 계층 통계\n",
    "level_counts = defaultdict(int)\n",
    "for h in hierarchy:\n",
    "    level_counts[h['level']] += 1\n",
    "\n",
    "print(\"\\n=== 계층 통계 ===\")\n",
    "for level in sorted(level_counts.keys()):\n",
    "    print(f\"Level {level}: {level_counts[level]}개\")\n",
    "\n",
    "print(\"\\n=== 계층 구조 샘플 (첫 15개) ===\")\n",
    "for i, item in enumerate(hierarchy[:15]):\n",
    "    indent = \"  \" * (item['level'] - 1)\n",
    "    conf_icon = \"✓\" if item['confidence'] == 'high' else \"~\" if item['confidence'] == 'medium' else \"?\"\n",
    "    print(f\"{conf_icon} {indent}L{item['level']}: {item['text'][:60]}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Part 3: 계층적 문서 구조 추출\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Part 3: 계층적 문서 구조\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def extract_hierarchical_document(doc, hierarchy):\n",
    "    \"\"\"계층 정보를 포함한 문서 구조 추출\"\"\"\n",
    "    \n",
    "    hierarchy_map = {h['text']: h for h in hierarchy}\n",
    "    \n",
    "    document_structure = {\n",
    "        'metadata': {\n",
    "            'filename': doc.name,\n",
    "            'pages': len(doc.pages),\n",
    "            'schema': doc.schema_name,\n",
    "            'version': doc.version\n",
    "        },\n",
    "        'content': []\n",
    "    }\n",
    "    \n",
    "    current_path = []  # 현재 섹션 경로\n",
    "    \n",
    "    for child_ref in doc.body.children:\n",
    "        if not hasattr(child_ref, 'cref'):\n",
    "            continue\n",
    "        \n",
    "        child = resolve_ref(doc, child_ref.cref)\n",
    "        if not child:\n",
    "            continue\n",
    "        \n",
    "        child_type = type(child).__name__\n",
    "        \n",
    "        if child_type == 'SectionHeaderItem':\n",
    "            text = child.text.strip()\n",
    "            \n",
    "            # 계층 정보 가져오기\n",
    "            hier_info = hierarchy_map.get(text, {'level': 1, 'confidence': 'low'})\n",
    "            \n",
    "            section = {\n",
    "                'type': 'section',\n",
    "                'title': text,\n",
    "                'page': child.prov[0].page_no if child.prov else None,\n",
    "                'level': hier_info['level'],\n",
    "                'confidence': hier_info['confidence'],\n",
    "                'content': []\n",
    "            }\n",
    "            \n",
    "            # 경로 업데이트\n",
    "            current_path = [p for p in current_path if p['level'] < hier_info['level']]\n",
    "            current_path.append(section)\n",
    "            \n",
    "            document_structure['content'].append(section)\n",
    "        \n",
    "        elif child_type == 'TextItem':\n",
    "            if hasattr(child, 'label') and str(child.label) not in ['page_header', 'page_footer']:\n",
    "                text_item = {\n",
    "                    'type': 'text',\n",
    "                    'content': child.text,\n",
    "                    'page': child.prov[0].page_no if child.prov else None,\n",
    "                    'label': str(child.label),\n",
    "                    'section_path': ' > '.join([p['title'] for p in current_path])\n",
    "                }\n",
    "                \n",
    "                if current_path:\n",
    "                    current_path[-1]['content'].append(text_item)\n",
    "                else:\n",
    "                    document_structure['content'].append(text_item)\n",
    "        \n",
    "        elif child_type == 'ListGroup':\n",
    "            list_group = {\n",
    "                'type': 'list',\n",
    "                'items': [],\n",
    "                'enumerated': bool(getattr(child, 'first_item_is_enumerated', False)),\n",
    "                'section_path': ' > '.join([p['title'] for p in current_path])\n",
    "            }\n",
    "            \n",
    "            for list_child_ref in child.children:\n",
    "                if hasattr(list_child_ref, 'cref'):\n",
    "                    list_child = resolve_ref(doc, list_child_ref.cref)\n",
    "                    if list_child and hasattr(list_child, 'text'):\n",
    "                        list_group['items'].append({\n",
    "                            'text': list_child.text,\n",
    "                            'page': list_child.prov[0].page_no if hasattr(list_child, 'prov') and list_child.prov else None\n",
    "                        })\n",
    "            \n",
    "            if current_path:\n",
    "                current_path[-1]['content'].append(list_group)\n",
    "            else:\n",
    "                document_structure['content'].append(list_group)\n",
    "        \n",
    "        elif child_type == 'TableItem':\n",
    "            table_item = {\n",
    "                'type': 'table',\n",
    "                'table_id': doc.tables.index(child),\n",
    "                'page': child.prov[0].page_no if child.prov else None,\n",
    "                'dimensions': {\n",
    "                    'rows': child.data.num_rows if hasattr(child, 'data') else None,\n",
    "                    'cols': child.data.num_cols if hasattr(child, 'data') else None\n",
    "                },\n",
    "                'markdown': safe_export_markdown(child),\n",
    "                'section_path': ' > '.join([p['title'] for p in current_path])\n",
    "            }\n",
    "            \n",
    "            if current_path:\n",
    "                current_path[-1]['content'].append(table_item)\n",
    "            else:\n",
    "                document_structure['content'].append(table_item)\n",
    "    \n",
    "    return document_structure\n",
    "\n",
    "hierarchical_doc = extract_hierarchical_document(doc, hierarchy)\n",
    "sections_count = sum(1 for item in hierarchical_doc['content'] if item['type'] == 'section')\n",
    "\n",
    "print(f\"총 최상위 항목: {len(hierarchical_doc['content'])}\")\n",
    "print(f\"섹션 수: {sections_count}\")\n",
    "\n",
    "# =============================================================================\n",
    "# Part 4: RAG 검색 인덱스 (노이즈 제거 포함)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Part 4: RAG 검색 인덱스 생성 (노이즈 제거)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 계층 경로 매핑\n",
    "hierarchy_map = {h['text']: h for h in hierarchy}\n",
    "current_path = []\n",
    "\n",
    "search_index = []\n",
    "\n",
    "# 텍스트 추가\n",
    "for text in new_dict['texts']:\n",
    "    if not hasattr(text, 'label'):\n",
    "        continue\n",
    "    \n",
    "    label = str(text.label)\n",
    "    \n",
    "    # 섹션 헤더면 경로 업데이트\n",
    "    if label == 'section_header':\n",
    "        text_str = text.text.strip()\n",
    "        if text_str in hierarchy_map:\n",
    "            level = hierarchy_map[text_str]['level']\n",
    "            current_path = [p for p in current_path if p['level'] < level]\n",
    "            current_path.append({'level': level, 'text': text_str})\n",
    "    \n",
    "    # 검색 인덱스에 추가\n",
    "    search_index.append({\n",
    "        'content': text.text,\n",
    "        'metadata': {\n",
    "            'page': text.prov[0].page_no if text.prov else None,\n",
    "            'type': 'text',\n",
    "            'label': label,\n",
    "            'section_path': ' > '.join([p['text'] for p in current_path]),\n",
    "            'section_level_1': current_path[0]['text'] if len(current_path) > 0 else None,\n",
    "            'section_level_2': current_path[1]['text'] if len(current_path) > 1 else None,\n",
    "            'section_level_3': current_path[2]['text'] if len(current_path) > 2 else None,\n",
    "        }\n",
    "    })\n",
    "\n",
    "# 테이블 행 추가\n",
    "for i, table in enumerate(new_dict['tables']):\n",
    "    page_no = table.prov[0].page_no if hasattr(table, 'prov') and table.prov else None\n",
    "    \n",
    "    if hasattr(table, 'data') and hasattr(table.data, 'grid'):\n",
    "        for row_idx, row in enumerate(table.data.grid):\n",
    "            row_text = ' | '.join([cell.text.strip() for cell in row])\n",
    "            \n",
    "            search_index.append({\n",
    "                'content': row_text,\n",
    "                'metadata': {\n",
    "                    'page': page_no,\n",
    "                    'type': 'table_row',\n",
    "                    'table_id': i,\n",
    "                    'row': row_idx,\n",
    "                    'section_path': ' > '.join([p['text'] for p in current_path]),\n",
    "                }\n",
    "            })\n",
    "\n",
    "print(f\"원본 인덱스: {len(search_index)}개\")\n",
    "\n",
    "# 노이즈 제거\n",
    "cleaner = SearchIndexCleaner()\n",
    "cleaned_index = cleaner.clean_search_index(search_index)\n",
    "\n",
    "print(f\"정제 후 인덱스: {len(cleaned_index)}개\")\n",
    "print(f\"제거율: {(len(search_index) - len(cleaned_index)) / len(search_index) * 100:.1f}%\")\n",
    "\n",
    "# =============================================================================\n",
    "# Part 5: 파일 저장\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Part 5: 파일 저장\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. 계층 구조 JSON\n",
    "with open('document_hierarchical.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(hierarchical_doc, f, ensure_ascii=False, indent=2)\n",
    "print(\"✓ document_hierarchical.json 저장 완료\")\n",
    "\n",
    "# 2. 계층 정보 JSON\n",
    "hierarchy_data = {\n",
    "    'metadata': {\n",
    "        'filename': new_dict['name'],\n",
    "        'total_sections': len(hierarchy),\n",
    "        'max_level': max(h['level'] for h in hierarchy) if hierarchy else 0\n",
    "    },\n",
    "    'hierarchy': hierarchy\n",
    "}\n",
    "\n",
    "with open('document_hierarchy.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(hierarchy_data, f, ensure_ascii=False, indent=2)\n",
    "print(\"✓ document_hierarchy.json 저장 완료\")\n",
    "\n",
    "# 3. 정제된 검색 인덱스 JSON\n",
    "with open('search_index_cleaned.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(cleaned_index, f, ensure_ascii=False, indent=2)\n",
    "print(\"✓ search_index_cleaned.json 저장 완료\")\n",
    "\n",
    "# 4. 통합 메타데이터\n",
    "full_metadata = {\n",
    "    'document': {\n",
    "        'filename': new_dict['name'],\n",
    "        'total_pages': len(new_dict['pages']),\n",
    "    },\n",
    "    'statistics': {\n",
    "        'texts': len(new_dict['texts']),\n",
    "        'sections': len(hierarchy),\n",
    "        'tables': len(new_dict['tables']),\n",
    "        'images': len(new_dict['pictures']),\n",
    "        'search_items_original': len(search_index),\n",
    "        'search_items_cleaned': len(cleaned_index),\n",
    "        'noise_removal_rate': f\"{(len(search_index) - len(cleaned_index)) / len(search_index) * 100:.1f}%\"\n",
    "    },\n",
    "    'text_labels': dict(label_counts),\n",
    "    'hierarchy_levels': dict(level_counts)\n",
    "}\n",
    "\n",
    "with open('document_metadata.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(full_metadata, f, ensure_ascii=False, indent=2)\n",
    "print(\"✓ document_metadata.json 저장 완료\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"완료! 생성된 파일:\")\n",
    "print(\"  - document_hierarchical.json (계층 구조)\")\n",
    "print(\"  - document_hierarchy.json (계층 정보)\")\n",
    "print(\"  - search_index_cleaned.json (정제된 RAG 인덱스)\")\n",
    "print(\"  - document_metadata.json (통합 메타데이터)\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "160ed931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PDF 일괄 처리 시작: 100개 파일\n",
      "================================================================================\n",
      "\n",
      "[1/100] 처리 중: 사단법인 보험개발원_실손보험 청구 전산화 시스템 구축 사업.pdf\n",
      "  ✓ 섹션: 135개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2058 → 1308개 (36.4% 제거)\n",
      "[2/100] 처리 중: 국가과학기술지식정보서비스_통합정보시스템 고도화 용역.pdf\n",
      "  ✓ 섹션: 115개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1872 → 931개 (50.3% 제거)\n",
      "[3/100] 처리 중: 나노종합기술원_스마트 팹 서비스 활용체계 구축관련 설비온라인 시스.pdf\n",
      "  ✓ 섹션: 77개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2392 → 903개 (62.2% 제거)\n",
      "[4/100] 처리 중: 부산관광공사_경영정보시스템 기능개선.pdf\n",
      "  ✓ 섹션: 182개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2527 → 1330개 (47.4% 제거)\n",
      "[5/100] 처리 중: 축산물품질평가원_축산물이력관리시스템 개선(정보화 사업).pdf\n",
      "  ✓ 섹션: 146개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2235 → 1133개 (49.3% 제거)\n",
      "[6/100] 처리 중: 재단법인스포츠윤리센터_스포츠윤리센터 LMS(학습지원시스템) 기능개선.pdf\n",
      "  ✓ 섹션: 144개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2340 → 1026개 (56.2% 제거)\n",
      "[7/100] 처리 중: 한국농수산식품유통공사_농산물가격안정기금 정부예산회계연계시스템 .pdf\n",
      "  ✓ 섹션: 108개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1499 → 839개 (44.0% 제거)\n",
      "[8/100] 처리 중: 대한상공회의소_기업 재생에너지 지원센터 홈페이지 개편 및 시스템 고.pdf\n",
      "  ✓ 섹션: 109개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2029 → 1004개 (50.5% 제거)\n",
      "[9/100] 처리 중: 한국수자원공사_용인 첨단 시스템반도체 국가산단 용수공급사업 타당성.pdf\n",
      "  ✓ 섹션: 169개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1511 → 939개 (37.9% 제거)\n",
      "[10/100] 처리 중: 세종테크노파크_세종테크노파크 인사정보 전산시스템 구축 용역 입찰공.pdf\n",
      "  ✓ 섹션: 144개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2306 → 1062개 (53.9% 제거)\n",
      "[11/100] 처리 중: 서민금융진흥원_서민금융진흥원 서민금융 채팅 상담시스템 구축.pdf\n",
      "  ✓ 섹션: 119개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2169 → 1029개 (52.6% 제거)\n",
      "[12/100] 처리 중: 파주도시관광공사_종량제봉투 판매관리 전산시스템 개선사업.pdf\n",
      "  ✓ 섹션: 198개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 3110 → 1487개 (52.2% 제거)\n",
      "[13/100] 처리 중: 국립인천해양박물관_국립인천해양박물관 해양자료관리시스템 구축 용.pdf\n",
      "  ✓ 섹션: 122개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1657 → 842개 (49.2% 제거)\n",
      "[14/100] 처리 중: 경기도 평택시_2024년도 평택시 버스정보시스템(BIS) 구축사업.pdf\n",
      "  ✓ 섹션: 184개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2017 → 1205개 (40.3% 제거)\n",
      "[15/100] 처리 중: 경기도사회서비스원_2024년 통합사회정보시스템 운영지원.pdf\n",
      "  ✓ 섹션: 108개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2431 → 1066개 (56.1% 제거)\n",
      "[16/100] 처리 중: 한국수자원공사_수도사업장 통합 사고분석솔루션 시범구축 용역.pdf\n",
      "  ✓ 섹션: 209개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2653 → 1400개 (47.2% 제거)\n",
      "[17/100] 처리 중: 한국원자력연구원_한국원자력연구원 선량평가시스템 고도화.pdf\n",
      "  ✓ 섹션: 129개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1092 → 714개 (34.6% 제거)\n",
      "[18/100] 처리 중: 서울특별시교육청_서울특별시교육청 지능정보화전략계획(ISP) 수립(2차) .pdf\n",
      "  ✓ 섹션: 146개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1690 → 898개 (46.9% 제거)\n",
      "[19/100] 처리 중: (사)벤처기업협회_2024년 벤처확인종합관리시스템 기능 고도화 용역사업 .pdf\n",
      "  ✓ 섹션: 150개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2796 → 1386개 (50.4% 제거)\n",
      "[20/100] 처리 중: 한국철도공사 (용역)_모바일오피스 시스템 고도화 용역(총체 및 1차).pdf\n",
      "  ✓ 섹션: 169개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 4021 → 1988개 (50.6% 제거)\n",
      "[21/100] 처리 중: 한국수출입은행_(긴급) 모잠비크 마푸토 지능형교통시스템(ITS) 구축사업.pdf\n",
      "  ✓ 섹션: 227개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2928 → 1473개 (49.7% 제거)\n",
      "[22/100] 처리 중: 대한장애인체육회_2025년 전국장애인체육대회 전산 및 시스템, 홈페이지 .pdf\n",
      "  ✓ 섹션: 101개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1098 → 594개 (45.9% 제거)\n",
      "[23/100] 처리 중: 대전대학교_대전대학교 2024학년도 다층적 융합 학습경험 플랫폼(MILE) 전.pdf\n",
      "  ✓ 섹션: 168개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1739 → 1026개 (41.0% 제거)\n",
      "[24/100] 처리 중: 전북대학교_JST 공유대학(원) xAPI기반 LRS시스템 구축.pdf\n",
      "  ✓ 섹션: 110개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1321 → 735개 (44.4% 제거)\n",
      "[25/100] 처리 중: 국민연금공단_사업장 사회보험료 지원 고시 개정에 따른 정보시스템 보.pdf\n",
      "  ✓ 섹션: 123개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1618 → 795개 (50.9% 제거)\n",
      "[26/100] 처리 중: 한국수자원공사_건설통합시스템(CMS) 고도화.pdf\n",
      "  ✓ 섹션: 249개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 3935 → 1570개 (60.1% 제거)\n",
      "[27/100] 처리 중: (사）한국대학스포츠협의회_KUSF 체육특기자 경기기록 관리시스템 개발.pdf\n",
      "  ✓ 섹션: 101개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1636 → 790개 (51.7% 제거)\n",
      "[28/100] 처리 중: 대한적십자사 의료원_적십자병원 병원정보 재해복구시스템 구축 용역 .pdf\n",
      "  ✓ 섹션: 95개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1448 → 689개 (52.4% 제거)\n",
      "[29/100] 처리 중: 을지대학교_을지대학교 비교과시스템 개발.pdf\n",
      "  ✓ 섹션: 128개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1652 → 1070개 (35.2% 제거)\n",
      "[30/100] 처리 중: 기초과학연구원_2025년도 중이온가속기용 극저온시스템 운전 용역.pdf\n",
      "  ✓ 섹션: 139개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1081 → 765개 (29.2% 제거)\n",
      "[31/100] 처리 중: 경희대학교_[입찰공고] 산학협력단 정보시스템 운영 용역업체 선정.pdf\n",
      "  ✓ 섹션: 80개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 868 → 556개 (35.9% 제거)\n",
      "[32/100] 처리 중: 국민연금공단_2024년 이러닝시스템 운영 용역.pdf\n",
      "  ✓ 섹션: 124개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1330 → 608개 (54.3% 제거)\n",
      "[33/100] 처리 중: (사)부산국제영화제_2024년 BIFF & ACFM 온라인서비스 재개발 및 행사지원시.pdf\n",
      "  ✓ 섹션: 104개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1409 → 907개 (35.6% 제거)\n",
      "[34/100] 처리 중: 서영대학교 산학협력단_전문대학 혁신지원사업 서영대학교 차세대 교육.pdf\n",
      "  ✓ 섹션: 151개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2732 → 1467개 (46.3% 제거)\n",
      "[35/100] 처리 중: 수협중앙회_강릉어선안전조업국 상황관제시스템 구축.pdf\n",
      "  ✓ 섹션: 98개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1276 → 638개 (50.0% 제거)\n",
      "[36/100] 처리 중: 남서울대학교_[혁신-국고] 남서울대학교 스마트 정보시스템 활성화(학사.pdf\n",
      "  ✓ 섹션: 181개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2781 → 1291개 (53.6% 제거)\n",
      "[37/100] 처리 중: 그랜드코리아레저(주)_2024년도 GKL  그룹웨어 시스템 구축 용역.pdf\n",
      "  ✓ 섹션: 165개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 3387 → 2120개 (37.4% 제거)\n",
      "[38/100] 처리 중: 한국농어촌공사_아세안+3 식량안보정보시스템(AFSIS) 3단계 협력(캄보디아.pdf\n",
      "  ✓ 섹션: 211개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 3141 → 1562개 (50.3% 제거)\n",
      "[39/100] 처리 중: 한국로봇산업진흥원_한국로봇산업진흥원 사업관리시스템 온라인평가 .pdf\n",
      "  ✓ 섹션: 116개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1464 → 846개 (42.2% 제거)\n",
      "[40/100] 처리 중: 사단법인아시아물위원회사무국_우즈벡-키르기즈스탄 기후변화대응 스.pdf\n",
      "  ✓ 섹션: 158개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1830 → 824개 (55.0% 제거)\n",
      "[41/100] 처리 중: 한국재정정보원_e나라도움 업무시스템 웹 접근성 컨설팅.pdf\n",
      "  ✓ 섹션: 164개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2239 → 1070개 (52.2% 제거)\n",
      "[42/100] 처리 중: 인천광역시 동구_수도국산달동네박물관 전시해설 시스템 구축(협상에 .pdf\n",
      "  ✓ 섹션: 153개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1976 → 964개 (51.2% 제거)\n",
      "[43/100] 처리 중: 국립중앙의료원_(긴급)「2024년도 차세대 응급의료 상황관리시스템 구축.pdf\n",
      "  ✓ 섹션: 213개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 3435 → 1926개 (43.9% 제거)\n",
      "[44/100] 처리 중: 고려대학교_차세대 포털·학사 정보시스템 구축사업.pdf\n",
      "  ✓ 섹션: 182개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 4413 → 2832개 (35.8% 제거)\n",
      "[45/100] 처리 중: 조선대학교_(재공고)2024 조선대학교 SW중심대학 사업관리시스템(WeHub) 구.pdf\n",
      "  ✓ 섹션: 121개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1234 → 930개 (24.6% 제거)\n",
      "[46/100] 처리 중: 한국해양조사협회_2024년 항해용 간행물 품질관리 업무보조 시스템 구축.pdf\n",
      "  ✓ 섹션: 152개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1619 → 923개 (43.0% 제거)\n",
      "[47/100] 처리 중: 한국건강가정진흥원_2025년 아이돌봄인력 인적성 검사 정보시스템 운영.pdf\n",
      "  ✓ 섹션: 133개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1493 → 892개 (40.3% 제거)\n",
      "[48/100] 처리 중: 한국연구재단_2024년 기초학문자료센터 시스템 운영 및 연구성과물 DB구.pdf\n",
      "  ✓ 섹션: 150개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1623 → 896개 (44.8% 제거)\n",
      "[49/100] 처리 중: 한국어촌어항공단_한국어촌어항공단 경영관리시스템(ERP·GW) 기능 고도.pdf\n",
      "  ✓ 섹션: 151개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1992 → 1079개 (45.8% 제거)\n",
      "[50/100] 처리 중: 중앙선거관리위원회_2025년도 행정정보시스템 위탁운영사업.pdf\n",
      "  ✓ 섹션: 216개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2285 → 1323개 (42.1% 제거)\n",
      "[51/100] 처리 중: 한국발명진흥회 입찰공고_2024년 건설기술에 관한 특허·실용신안 활용실.pdf\n",
      "  ✓ 섹션: 120개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1818 → 925개 (49.1% 제거)\n",
      "[52/100] 처리 중: 한국생산기술연구원_2세대 전자조달시스템  기반구축사업.pdf\n",
      "  ✓ 섹션: 136개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1729 → 1115개 (35.5% 제거)\n",
      "[53/100] 처리 중: 대검찰청_아태 사이버범죄 역량강화 허브(APC-HUB) 홈페이지 및 온라인 교.pdf\n",
      "  ✓ 섹션: 109개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1975 → 801개 (59.4% 제거)\n",
      "[54/100] 처리 중: 서울특별시 여성가족재단_(재공고, 협상) 서울 디지털성범죄 안심지원센.pdf\n",
      "  ✓ 섹션: 192개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 3721 → 1864개 (49.9% 제거)\n",
      "[55/100] 처리 중: 울산광역시_2024년 버스정보시스템 확대 구축 및 기능개선 용역.pdf\n",
      "  ✓ 섹션: 150개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2377 → 1187개 (50.1% 제거)\n",
      "[56/100] 처리 중: 한국지식재산보호원_IP-NAVI  해외지식재산센터 사업관리 시스템 기능개.pdf\n",
      "  ✓ 섹션: 151개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1935 → 1031개 (46.7% 제거)\n",
      "[57/100] 처리 중: 한국보육진흥원_연차별 자율 품질관리 시스템 기능개선.pdf\n",
      "  ✓ 섹션: 83개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1507 → 833개 (44.7% 제거)\n",
      "[58/100] 처리 중: 한국연구재단_2024년 대학산학협력활동 실태조사 시스템(UICC) 기능개선.pdf\n",
      "  ✓ 섹션: 140개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1851 → 1071개 (42.1% 제거)\n",
      "[59/100] 처리 중: 재단법인충북연구원_GIS통계 기반 재난안전데이터 분석ㆍ관리 시스템 구.pdf\n",
      "  ✓ 섹션: 110개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1129 → 753개 (33.3% 제거)\n",
      "[60/100] 처리 중: 한국수자원조사기술원_수문자료정보관리시스템(HDIMS) 재구축 용역(3단계.pdf\n",
      "  ✓ 섹션: 145개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2271 → 1094개 (51.8% 제거)\n",
      "[61/100] 처리 중: 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf\n",
      "  ✓ 섹션: 168개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2584 → 1620개 (37.3% 제거)\n",
      "[62/100] 처리 중: 한국보건산업진흥원_의료기기산업 종합정보시스템(정보관리기관) 기능.pdf\n",
      "  ✓ 섹션: 128개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2013 → 1146개 (43.1% 제거)\n",
      "[63/100] 처리 중: 한국사회보장정보원_라오스 보건의료정보화 협력을 위한 사전타당성 조.pdf\n",
      "  ✓ 섹션: 128개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1420 → 765개 (46.1% 제거)\n",
      "[64/100] 처리 중: 2025 구미 아시아육상경기선수권대회 조직위원회_2025 구미아시아육상경.pdf\n",
      "  ✓ 섹션: 96개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1157 → 505개 (56.4% 제거)\n",
      "[65/100] 처리 중: 한국교육과정평가원_국가교육과정정보센터(NCIC) 시스템 운영 및 개선.pdf\n",
      "  ✓ 섹션: 103개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1283 → 673개 (47.5% 제거)\n",
      "[66/100] 처리 중: 한국철도공사 (용역)_예약발매시스템 개량 ISMP 용역.pdf\n",
      "  ✓ 섹션: 147개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2035 → 1157개 (43.1% 제거)\n",
      "[67/100] 처리 중: 국가철도공단_철도인프라 디지털트윈 정보화전략계획(ISP) 수립 용역(변.pdf\n",
      "  ✓ 섹션: 135개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1762 → 923개 (47.6% 제거)\n",
      "[68/100] 처리 중: BioIN_의료기기산업 종합정보시스템(정보관리기관) 기능개선 사업(2차).pdf\n",
      "  ✓ 섹션: 128개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2013 → 1146개 (43.1% 제거)\n",
      "[69/100] 처리 중: 한국사학진흥재단_대학재정정보시스템(기본재산 및 기채 사후관리) 고.pdf\n",
      "  ✓ 섹션: 174개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2700 → 1453개 (46.2% 제거)\n",
      "[70/100] 처리 중: 인천광역시_인천일자리플랫폼 정보시스템 구축 ISP 수립용역.pdf\n",
      "  ✓ 섹션: 164개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1576 → 750개 (52.4% 제거)\n",
      "[71/100] 처리 중: 재단법인 한국장애인문화예술원_2024년 장애인문화예술정보시스템 이음.pdf\n",
      "  ✓ 섹션: 106개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1159 → 691개 (40.4% 제거)\n",
      "[72/100] 처리 중: 문화체육관광부 국립민속박물관_2024년 국립민속박물관 민속아카이브 자.pdf\n",
      "  ✓ 섹션: 141개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2111 → 932개 (55.9% 제거)\n",
      "[73/100] 처리 중: 재단법인경기도일자리재단_2025년 통합접수시스템 운영.pdf\n",
      "  ✓ 섹션: 152개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2823 → 1673개 (40.7% 제거)\n",
      "[74/100] 처리 중: KOICA 전자조달_[긴급] [지문] [국제] 우즈베키스탄 열린 의정활동 상하원 .pdf\n",
      "  ✓ 섹션: 196개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 3849 → 1930개 (49.9% 제거)\n",
      "[75/100] 처리 중: 인천광역시_도시계획위원회 통합관리시스템 구축용역.pdf\n",
      "  ✓ 섹션: 114개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1702 → 990개 (41.8% 제거)\n",
      "[76/100] 처리 중: 한국농어촌공사_네팔 수자원관리 정보화사업-Pilot 시스템 구축용역.pdf\n",
      "  ✓ 섹션: 163개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2433 → 1452개 (40.3% 제거)\n",
      "[77/100] 처리 중: 고양도시관리공사_관산근린공원 다목적구장 홈페이지 및 회원 통합운영.pdf\n",
      "  ✓ 섹션: 145개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1680 → 950개 (43.5% 제거)\n",
      "[78/100] 처리 중: 경기도 안양시_호계체육관 배드민턴장 및 탁구장 예약시스템 구축 용역.pdf\n",
      "  ✓ 섹션: 167개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1886 → 943개 (50.0% 제거)\n",
      "[79/100] 처리 중: 한국산업단지공단_산단 안전정보시스템 1차 구축 용역.pdf\n",
      "  ✓ 섹션: 136개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2847 → 1380개 (51.5% 제거)\n",
      "[80/100] 처리 중: 한국한의학연구원_통합정보시스템 고도화 용역.pdf\n",
      "  ✓ 섹션: 115개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1872 → 931개 (50.3% 제거)\n",
      "[81/100] 처리 중: (재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅.pdf\n",
      "  ✓ 섹션: 120개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1318 → 669개 (49.2% 제거)\n",
      "[82/100] 처리 중: 한국생산기술연구원_EIP3.0 고압가스 안전관리 시스템 구축 용역.pdf\n",
      "  ✓ 섹션: 180개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2937 → 1519개 (48.3% 제거)\n",
      "[83/100] 처리 중: 수협중앙회_수협중앙회 수산물사이버직매장 시스템 재구축 ISMP 수립 입.pdf\n",
      "  ✓ 섹션: 137개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1534 → 911개 (40.6% 제거)\n",
      "[84/100] 처리 중: 한국철도공사 (용역)_[재공고][긴급][협상형]운행정보기록 자동분석시스.pdf\n",
      "  ✓ 섹션: 169개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2425 → 1463개 (39.7% 제거)\n",
      "[85/100] 처리 중: 국방과학연구소_기록관리시스템 통합 활용 및 보안 환경 구축.pdf\n",
      "  ✓ 섹션: 113개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1880 → 872개 (53.6% 제거)\n",
      "[86/100] 처리 중: 재단법인 광주연구원_광주정책연구아카이브(GPA) 시스템 개발.pdf\n",
      "  ✓ 섹션: 164개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2355 → 1043개 (55.7% 제거)\n",
      "[87/100] 처리 중: 한국산업인력공단_RFID기반 국가자격 시험 결과물 스마트 관리시스템 도.pdf\n",
      "  ✓ 섹션: 73개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1107 → 633개 (42.8% 제거)\n",
      "[88/100] 처리 중: 광주과학기술원_실시간통합연구비관리시스템(RCMS)  연계 모듈 변경 사업.pdf\n",
      "  ✓ 섹션: 161개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1828 → 858개 (53.1% 제거)\n",
      "[89/100] 처리 중: 한영대학_한영대학교 특성화 맞춤형 교육환경 구축 - 트랙운영 학사정보.pdf\n",
      "  ✓ 섹션: 108개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1173 → 795개 (32.2% 제거)\n",
      "[90/100] 처리 중: 재단법인 광주광역시 광주문화재단_2024년 광주문화예술통합플랫폼 시스.pdf\n",
      "  ✓ 섹션: 138개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1783 → 907개 (49.1% 제거)\n",
      "[91/100] 처리 중: 서울시립대학교_[사전공개] 학업성취도 다차원 종단분석 통합시스템 1차.pdf\n",
      "  ✓ 섹션: 241개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2914 → 1885개 (35.3% 제거)\n",
      "[92/100] 처리 중: 케빈랩 주식회사_평택시 강소형 스마트시티 AI 기반의 영상감시 시스템 .pdf\n",
      "  ✓ 섹션: 149개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1624 → 869개 (46.5% 제거)\n",
      "[93/100] 처리 중: 국방과학연구소_대용량 자료전송시스템 고도화.pdf\n",
      "  ✓ 섹션: 108개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1710 → 834개 (51.2% 제거)\n",
      "[94/100] 처리 중: 광주과학기술원_학사시스템 기능개선 사업.pdf\n",
      "  ✓ 섹션: 138개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1290 → 594개 (54.0% 제거)\n",
      "[95/100] 처리 중: 전북특별자치도 정읍시_정읍체육트레이닝센터 통합운영관리시스템 구.pdf\n",
      "  ✓ 섹션: 187개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 2539 → 1352개 (46.8% 제거)\n",
      "[96/100] 처리 중: 인천공항운영서비스(주)_인천공항운영서비스㈜ 차세대 ERP시스템 구축 .pdf\n",
      "  ✓ 섹션: 72개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1477 → 829개 (43.9% 제거)\n",
      "[97/100] 처리 중: 경상북도 봉화군_봉화군 재난통합관리시스템 고도화 사업(협상)(긴급).pdf\n",
      "  ✓ 섹션: 122개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1476 → 753개 (49.0% 제거)\n",
      "[98/100] 처리 중: 축산물품질평가원_꿀 품질평가 전산시스템 기능개선 사업.pdf\n",
      "  ✓ 섹션: 136개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1686 → 977개 (42.1% 제거)\n",
      "[99/100] 처리 중: 한국전기안전공사_전기안전 관제시스템 보안 모듈 개발 용역.pdf\n",
      "  ✓ 섹션: 113개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 1670 → 886개 (46.9% 제거)\n",
      "[100/100] 처리 중: 한국가스공사_[재공고]차세대 통합정보시스템(ERP) 구축.pdf\n",
      "  ✓ 섹션: 102개\n",
      "  ✓ 계층: 4단계\n",
      "  ✓ 검색 인덱스: 3383 → 1673개 (50.5% 제거)\n",
      "\n",
      "================================================================================\n",
      "처리 완료!\n",
      "================================================================================\n",
      "성공: 100개\n",
      "실패: 0개\n",
      "총 섹션: 14200개\n",
      "총 페이지: 9517개\n",
      "평균 섹션/문서: 142.0개\n",
      "\n",
      "생성된 파일:\n",
      "  - /Users/won/dev/00_codeit/0_mission/200_DL_RAG/data/all_hierarchies.json (전체 계층 정보)\n",
      "  - /Users/won/dev/00_codeit/0_mission/200_DL_RAG/data/processing_report.json (처리 리포트)\n",
      "  - /Users/won/dev/00_codeit/0_mission/200_DL_RAG/data/{name}_*.json (개별 PDF 파일들)\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def build_tree(hierarchy):\n",
    "    \"\"\"계층을 트리 구조로 변환\"\"\"\n",
    "    tree = []\n",
    "    stack = []  # (level, node)\n",
    "    \n",
    "    for item in hierarchy:\n",
    "        node = {\n",
    "            'text': item['text'],\n",
    "            'level': item['level'],\n",
    "            'page': item['page'],\n",
    "            'children': []\n",
    "        }\n",
    "        \n",
    "        # 스택에서 현재 레벨보다 같거나 낮은 레벨 제거\n",
    "        while stack and stack[-1][0] >= item['level']:\n",
    "            stack.pop()\n",
    "        \n",
    "        if stack:\n",
    "            # 부모에 추가\n",
    "            stack[-1][1]['children'].append(node)\n",
    "        else:\n",
    "            # 최상위 노드\n",
    "            tree.append(node)\n",
    "        \n",
    "        stack.append((item['level'], node))\n",
    "    \n",
    "    return tree\n",
    "\n",
    "def process_single_pdf(pdf_path, detector, cleaner, doc_converter):\n",
    "    \"\"\"단일 PDF 완전 처리\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # 1. PDF 파싱\n",
    "        doc = doc_converter.convert(str(pdf_path)).document\n",
    "        \n",
    "        # 2. new_dict 생성\n",
    "        new_dict = dict()\n",
    "        for tuple_ in list(doc):\n",
    "            new_dict[tuple_[0]] = tuple_[1]\n",
    "        \n",
    "        # 3. 섹션 헤더 추출 및 계층 추론\n",
    "        section_headers = [\n",
    "            t for t in new_dict['texts'] \n",
    "            if hasattr(t, 'label') and str(t.label) == 'section_header'\n",
    "        ]\n",
    "        hierarchy = detector.infer_hierarchy(section_headers)\n",
    "        tree = build_tree(hierarchy)\n",
    "        \n",
    "        # 4. 계층적 문서 구조 추출\n",
    "        hierarchy_map = {h['text']: h for h in hierarchy}\n",
    "        current_path = []\n",
    "        \n",
    "        hierarchical_doc = {\n",
    "            'metadata': {\n",
    "                'filename': doc.name,\n",
    "                'pages': len(new_dict['pages']),\n",
    "                'schema': new_dict['schema_name'],\n",
    "                'version': new_dict['version']\n",
    "            },\n",
    "            'content': []\n",
    "        }\n",
    "        \n",
    "        # Body의 children 순회\n",
    "        for child_ref in doc.body.children:\n",
    "            if not hasattr(child_ref, 'cref'):\n",
    "                continue\n",
    "            \n",
    "            child = resolve_ref(doc, child_ref.cref)\n",
    "            if not child:\n",
    "                continue\n",
    "            \n",
    "            child_type = type(child).__name__\n",
    "            \n",
    "            if child_type == 'SectionHeaderItem':\n",
    "                text = child.text.strip()\n",
    "                hier_info = hierarchy_map.get(text, {'level': 1, 'confidence': 'low'})\n",
    "                \n",
    "                section = {\n",
    "                    'type': 'section',\n",
    "                    'title': text,\n",
    "                    'page': child.prov[0].page_no if child.prov else None,\n",
    "                    'level': hier_info['level'],\n",
    "                    'content': []\n",
    "                }\n",
    "                \n",
    "                current_path = [p for p in current_path if p['level'] < hier_info['level']]\n",
    "                current_path.append(section)\n",
    "                hierarchical_doc['content'].append(section)\n",
    "        \n",
    "        # 5. 검색 인덱스 생성 (노이즈 제거 포함)\n",
    "        search_index = []\n",
    "        current_path_for_search = []\n",
    "        \n",
    "        for text in new_dict['texts']:\n",
    "            if not hasattr(text, 'label'):\n",
    "                continue\n",
    "            \n",
    "            label = str(text.label)\n",
    "            \n",
    "            # 섹션 경로 업데이트\n",
    "            if label == 'section_header':\n",
    "                text_str = text.text.strip()\n",
    "                if text_str in hierarchy_map:\n",
    "                    level = hierarchy_map[text_str]['level']\n",
    "                    current_path_for_search = [p for p in current_path_for_search if p['level'] < level]\n",
    "                    current_path_for_search.append({'level': level, 'text': text_str})\n",
    "            \n",
    "            search_index.append({\n",
    "                'content': text.text,\n",
    "                'metadata': {\n",
    "                    'page': text.prov[0].page_no if text.prov else None,\n",
    "                    'type': 'text',\n",
    "                    'label': label,\n",
    "                    'section_path': ' > '.join([p['text'] for p in current_path_for_search]),\n",
    "                    'section_level_1': current_path_for_search[0]['text'] if len(current_path_for_search) > 0 else None,\n",
    "                    'section_level_2': current_path_for_search[1]['text'] if len(current_path_for_search) > 1 else None,\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        # 테이블 행 추가\n",
    "        for i, table in enumerate(new_dict['tables']):\n",
    "            page_no = table.prov[0].page_no if hasattr(table, 'prov') and table.prov else None\n",
    "            \n",
    "            if hasattr(table, 'data') and hasattr(table.data, 'grid'):\n",
    "                for row_idx, row in enumerate(table.data.grid):\n",
    "                    row_text = ' | '.join([cell.text.strip() for cell in row])\n",
    "                    \n",
    "                    search_index.append({\n",
    "                        'content': row_text,\n",
    "                        'metadata': {\n",
    "                            'page': page_no,\n",
    "                            'type': 'table_row',\n",
    "                            'table_id': i,\n",
    "                            'row': row_idx,\n",
    "                            'section_path': ' > '.join([p['text'] for p in current_path_for_search]),\n",
    "                        }\n",
    "                    })\n",
    "        \n",
    "        # 노이즈 제거\n",
    "        cleaned_index = cleaner.clean_search_index(search_index)\n",
    "        \n",
    "        # 6. 통계\n",
    "        from collections import Counter\n",
    "        labels = [str(t.label) for t in new_dict['texts'] if hasattr(t, 'label')]\n",
    "        label_counts = Counter(labels)\n",
    "        \n",
    "        level_counts = {}\n",
    "        for h in hierarchy:\n",
    "            level_counts[h['level']] = level_counts.get(h['level'], 0) + 1\n",
    "        \n",
    "        # 7. 결과 반환\n",
    "        return {\n",
    "            'success': True,\n",
    "            'filename': pdf_path.name,\n",
    "            'data': {\n",
    "                'metadata': {\n",
    "                    'filename': doc.name,\n",
    "                    'total_pages': len(new_dict['pages']),\n",
    "                    'total_sections': len(hierarchy),\n",
    "                    'max_level': max(h['level'] for h in hierarchy) if hierarchy else 0,\n",
    "                    'total_texts': len(new_dict['texts']),\n",
    "                    'total_tables': len(new_dict['tables']),\n",
    "                    'total_images': len(new_dict['pictures']),\n",
    "                },\n",
    "                'statistics': {\n",
    "                    'search_items_original': len(search_index),\n",
    "                    'search_items_cleaned': len(cleaned_index),\n",
    "                    'noise_removal_rate': f\"{(len(search_index) - len(cleaned_index)) / len(search_index) * 100:.1f}%\",\n",
    "                    'text_labels': dict(label_counts),\n",
    "                    'hierarchy_levels': level_counts\n",
    "                },\n",
    "                'hierarchy': hierarchy,\n",
    "                'tree': tree,\n",
    "                'hierarchical_structure': hierarchical_doc,\n",
    "                'search_index_cleaned': cleaned_index\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'filename': pdf_path.name,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "def process_all_pdfs(pdf_dir, output_dir, doc_converter):\n",
    "    \"\"\"\n",
    "    100개 PDF 일괄 처리 (완전판)\n",
    "    \n",
    "    각 PDF마다 생성:\n",
    "    - {name}_hierarchy.json (계층 정보)\n",
    "    - {name}_hierarchical.json (계층 구조)\n",
    "    - {name}_search_index.json (정제된 검색 인덱스)\n",
    "    - {name}_metadata.json (메타데이터)\n",
    "    \n",
    "    전체 통합:\n",
    "    - all_hierarchies.json (모든 PDF 계층 정보)\n",
    "    - processing_report.json (처리 결과 리포트)\n",
    "    \"\"\"\n",
    "    \n",
    "    pdf_files = list(Path(pdf_dir).glob(\"*.pdf\"))\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 클래스 초기화\n",
    "    detector = HierarchyDetector()\n",
    "    cleaner = SearchIndexCleaner()\n",
    "    \n",
    "    # 결과 저장\n",
    "    all_results = {}\n",
    "    processing_log = {\n",
    "        'start_time': datetime.now().isoformat(),\n",
    "        'total_files': len(pdf_files),\n",
    "        'success_count': 0,\n",
    "        'failed_count': 0,\n",
    "        'failed_files': [],\n",
    "        'summary': {}\n",
    "    }\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"PDF 일괄 처리 시작: {len(pdf_files)}개 파일\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    for i, pdf_path in enumerate(pdf_files):\n",
    "        print(f\"[{i+1}/{len(pdf_files)}] 처리 중: {pdf_path.name}\")\n",
    "        \n",
    "        # 처리\n",
    "        result = process_single_pdf(pdf_path, detector, cleaner, doc_converter)\n",
    "        \n",
    "        if result['success']:\n",
    "            doc_name = pdf_path.stem\n",
    "            data = result['data']\n",
    "            \n",
    "            # 개별 파일 저장\n",
    "            # 1. 계층 정보\n",
    "            # with open(output_path / f\"{doc_name}_hierarchy.json\", 'w', encoding='utf-8') as f:\n",
    "            #     json.dump({\n",
    "            #         'metadata': data['metadata'],\n",
    "            #         'hierarchy': data['hierarchy'],\n",
    "            #         'tree': data['tree']\n",
    "            #     }, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            # # 2. 계층 구조\n",
    "            # with open(output_path / f\"{doc_name}_hierarchical.json\", 'w', encoding='utf-8') as f:\n",
    "            #     json.dump(data['hierarchical_structure'], f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            # # 3. 정제된 검색 인덱스\n",
    "            # with open(output_path / f\"{doc_name}_search_index.json\", 'w', encoding='utf-8') as f:\n",
    "            #     json.dump(data['search_index_cleaned'], f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            # # 4. 메타데이터\n",
    "            # with open(output_path / f\"{doc_name}_metadata.json\", 'w', encoding='utf-8') as f:\n",
    "            #     json.dump({\n",
    "            #         'metadata': data['metadata'],\n",
    "            #         'statistics': data['statistics']\n",
    "            #     }, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            # 전체 결과에 추가\n",
    "            all_results[doc_name] = {\n",
    "                'filename': result['filename'],\n",
    "                'metadata': data['metadata'],\n",
    "                'statistics': data['statistics']\n",
    "            }\n",
    "            \n",
    "            processing_log['success_count'] += 1\n",
    "            \n",
    "            print(f\"  ✓ 섹션: {data['metadata']['total_sections']}개\")\n",
    "            print(f\"  ✓ 계층: {data['metadata']['max_level']}단계\")\n",
    "            print(f\"  ✓ 검색 인덱스: {data['statistics']['search_items_original']} → {data['statistics']['search_items_cleaned']}개 ({data['statistics']['noise_removal_rate']} 제거)\")\n",
    "        \n",
    "        else:\n",
    "            processing_log['failed_count'] += 1\n",
    "            processing_log['failed_files'].append({\n",
    "                'filename': result['filename'],\n",
    "                'error': result['error']\n",
    "            })\n",
    "            print(f\"  ✗ 실패: {result['error']}\")\n",
    "    \n",
    "    # 전체 통합 파일 저장\n",
    "    with open(output_path / 'all_hierarchies.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_results, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # 처리 리포트\n",
    "    processing_log['end_time'] = datetime.now().isoformat()\n",
    "    processing_log['summary'] = {\n",
    "        'total_sections': sum(r['metadata']['total_sections'] for r in all_results.values()),\n",
    "        'total_pages': sum(r['metadata']['total_pages'] for r in all_results.values()),\n",
    "        'avg_sections_per_doc': sum(r['metadata']['total_sections'] for r in all_results.values()) / len(all_results) if all_results else 0,\n",
    "    }\n",
    "    \n",
    "    with open(output_path / 'processing_report.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(processing_log, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"처리 완료!\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"성공: {processing_log['success_count']}개\")\n",
    "    print(f\"실패: {processing_log['failed_count']}개\")\n",
    "    print(f\"총 섹션: {processing_log['summary']['total_sections']}개\")\n",
    "    print(f\"총 페이지: {processing_log['summary']['total_pages']}개\")\n",
    "    print(f\"평균 섹션/문서: {processing_log['summary']['avg_sections_per_doc']:.1f}개\")\n",
    "    \n",
    "    if processing_log['failed_files']:\n",
    "        print(f\"\\n실패한 파일:\")\n",
    "        for failed in processing_log['failed_files']:\n",
    "            print(f\"  - {failed['filename']}: {failed['error']}\")\n",
    "    \n",
    "    print(f\"\\n생성된 파일:\")\n",
    "    print(f\"  - {output_path}/all_hierarchies.json (전체 계층 정보)\")\n",
    "    print(f\"  - {output_path}/processing_report.json (처리 리포트)\")\n",
    "    print(f\"  - {output_path}/{{name}}_*.json (개별 PDF 파일들)\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return all_results, processing_log\n",
    "\n",
    "# =============================================================================\n",
    "# 실행\n",
    "# =============================================================================\n",
    "\n",
    "# 예시:\n",
    "all_results, report = process_all_pdfs(RAW_DIR, DATA_DIR, doc_converter)\n",
    "\n",
    "# 또는 테스트용 (첫 3개만)\n",
    "# test_files = list(Path(RAW_DIR).glob(\"*.pdf\"))[:3]\n",
    "# for pdf in test_files:\n",
    "#     result = process_single_pdf(pdf, HierarchyDetector(), SearchIndexCleaner(), doc_converter)\n",
    "#     print(f\"{pdf.name}: {'✓' if result['success'] else '✗'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da35dc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PDF 일괄 처리 시작: 100개 파일\n",
      "================================================================================\n",
      "\n",
      "[1/100] 처리 중: 사단법인 보험개발원_실손보험 청구 전산화 시스템 구축 사업.pdf\n",
      "  ✓ 검색 항목: 1308개\n",
      "  ✓ 섹션: 135개\n",
      "[2/100] 처리 중: 국가과학기술지식정보서비스_통합정보시스템 고도화 용역.pdf\n",
      "  ✓ 검색 항목: 931개\n",
      "  ✓ 섹션: 115개\n",
      "[3/100] 처리 중: 나노종합기술원_스마트 팹 서비스 활용체계 구축관련 설비온라인 시스.pdf\n",
      "  ✓ 검색 항목: 903개\n",
      "  ✓ 섹션: 77개\n",
      "[4/100] 처리 중: 부산관광공사_경영정보시스템 기능개선.pdf\n",
      "  ✓ 검색 항목: 1330개\n",
      "  ✓ 섹션: 182개\n",
      "[5/100] 처리 중: 축산물품질평가원_축산물이력관리시스템 개선(정보화 사업).pdf\n",
      "  ✓ 검색 항목: 1133개\n",
      "  ✓ 섹션: 146개\n",
      "[6/100] 처리 중: 재단법인스포츠윤리센터_스포츠윤리센터 LMS(학습지원시스템) 기능개선.pdf\n",
      "  ✓ 검색 항목: 1026개\n",
      "  ✓ 섹션: 144개\n",
      "[7/100] 처리 중: 한국농수산식품유통공사_농산물가격안정기금 정부예산회계연계시스템 .pdf\n",
      "  ✓ 검색 항목: 839개\n",
      "  ✓ 섹션: 108개\n",
      "[8/100] 처리 중: 대한상공회의소_기업 재생에너지 지원센터 홈페이지 개편 및 시스템 고.pdf\n",
      "  ✓ 검색 항목: 1004개\n",
      "  ✓ 섹션: 109개\n",
      "[9/100] 처리 중: 한국수자원공사_용인 첨단 시스템반도체 국가산단 용수공급사업 타당성.pdf\n",
      "  ✓ 검색 항목: 939개\n",
      "  ✓ 섹션: 169개\n",
      "[10/100] 처리 중: 세종테크노파크_세종테크노파크 인사정보 전산시스템 구축 용역 입찰공.pdf\n",
      "  ✓ 검색 항목: 1062개\n",
      "  ✓ 섹션: 144개\n",
      "[11/100] 처리 중: 서민금융진흥원_서민금융진흥원 서민금융 채팅 상담시스템 구축.pdf\n",
      "  ✓ 검색 항목: 1029개\n",
      "  ✓ 섹션: 119개\n",
      "[12/100] 처리 중: 파주도시관광공사_종량제봉투 판매관리 전산시스템 개선사업.pdf\n",
      "  ✓ 검색 항목: 1487개\n",
      "  ✓ 섹션: 198개\n",
      "[13/100] 처리 중: 국립인천해양박물관_국립인천해양박물관 해양자료관리시스템 구축 용.pdf\n",
      "  ✓ 검색 항목: 842개\n",
      "  ✓ 섹션: 122개\n",
      "[14/100] 처리 중: 경기도 평택시_2024년도 평택시 버스정보시스템(BIS) 구축사업.pdf\n",
      "  ✓ 검색 항목: 1205개\n",
      "  ✓ 섹션: 184개\n",
      "[15/100] 처리 중: 경기도사회서비스원_2024년 통합사회정보시스템 운영지원.pdf\n",
      "  ✓ 검색 항목: 1066개\n",
      "  ✓ 섹션: 108개\n",
      "[16/100] 처리 중: 한국수자원공사_수도사업장 통합 사고분석솔루션 시범구축 용역.pdf\n",
      "  ✓ 검색 항목: 1400개\n",
      "  ✓ 섹션: 209개\n",
      "[17/100] 처리 중: 한국원자력연구원_한국원자력연구원 선량평가시스템 고도화.pdf\n",
      "  ✓ 검색 항목: 714개\n",
      "  ✓ 섹션: 129개\n",
      "[18/100] 처리 중: 서울특별시교육청_서울특별시교육청 지능정보화전략계획(ISP) 수립(2차) .pdf\n",
      "  ✓ 검색 항목: 898개\n",
      "  ✓ 섹션: 146개\n",
      "[19/100] 처리 중: (사)벤처기업협회_2024년 벤처확인종합관리시스템 기능 고도화 용역사업 .pdf\n",
      "  ✓ 검색 항목: 1386개\n",
      "  ✓ 섹션: 150개\n",
      "[20/100] 처리 중: 한국철도공사 (용역)_모바일오피스 시스템 고도화 용역(총체 및 1차).pdf\n",
      "  ✓ 검색 항목: 1988개\n",
      "  ✓ 섹션: 169개\n",
      "[21/100] 처리 중: 한국수출입은행_(긴급) 모잠비크 마푸토 지능형교통시스템(ITS) 구축사업.pdf\n",
      "  ✓ 검색 항목: 1473개\n",
      "  ✓ 섹션: 227개\n",
      "[22/100] 처리 중: 대한장애인체육회_2025년 전국장애인체육대회 전산 및 시스템, 홈페이지 .pdf\n",
      "  ✓ 검색 항목: 594개\n",
      "  ✓ 섹션: 101개\n",
      "[23/100] 처리 중: 대전대학교_대전대학교 2024학년도 다층적 융합 학습경험 플랫폼(MILE) 전.pdf\n",
      "  ✓ 검색 항목: 1026개\n",
      "  ✓ 섹션: 168개\n",
      "[24/100] 처리 중: 전북대학교_JST 공유대학(원) xAPI기반 LRS시스템 구축.pdf\n",
      "  ✓ 검색 항목: 735개\n",
      "  ✓ 섹션: 110개\n",
      "[25/100] 처리 중: 국민연금공단_사업장 사회보험료 지원 고시 개정에 따른 정보시스템 보.pdf\n",
      "  ✓ 검색 항목: 795개\n",
      "  ✓ 섹션: 123개\n",
      "[26/100] 처리 중: 한국수자원공사_건설통합시스템(CMS) 고도화.pdf\n",
      "  ✓ 검색 항목: 1570개\n",
      "  ✓ 섹션: 249개\n",
      "[27/100] 처리 중: (사）한국대학스포츠협의회_KUSF 체육특기자 경기기록 관리시스템 개발.pdf\n",
      "  ✓ 검색 항목: 790개\n",
      "  ✓ 섹션: 101개\n",
      "[28/100] 처리 중: 대한적십자사 의료원_적십자병원 병원정보 재해복구시스템 구축 용역 .pdf\n",
      "  ✓ 검색 항목: 689개\n",
      "  ✓ 섹션: 95개\n",
      "[29/100] 처리 중: 을지대학교_을지대학교 비교과시스템 개발.pdf\n",
      "  ✓ 검색 항목: 1070개\n",
      "  ✓ 섹션: 128개\n",
      "[30/100] 처리 중: 기초과학연구원_2025년도 중이온가속기용 극저온시스템 운전 용역.pdf\n",
      "  ✓ 검색 항목: 765개\n",
      "  ✓ 섹션: 139개\n",
      "[31/100] 처리 중: 경희대학교_[입찰공고] 산학협력단 정보시스템 운영 용역업체 선정.pdf\n",
      "  ✓ 검색 항목: 556개\n",
      "  ✓ 섹션: 80개\n",
      "[32/100] 처리 중: 국민연금공단_2024년 이러닝시스템 운영 용역.pdf\n",
      "  ✓ 검색 항목: 608개\n",
      "  ✓ 섹션: 124개\n",
      "[33/100] 처리 중: (사)부산국제영화제_2024년 BIFF & ACFM 온라인서비스 재개발 및 행사지원시.pdf\n",
      "  ✓ 검색 항목: 907개\n",
      "  ✓ 섹션: 104개\n",
      "[34/100] 처리 중: 서영대학교 산학협력단_전문대학 혁신지원사업 서영대학교 차세대 교육.pdf\n",
      "  ✓ 검색 항목: 1467개\n",
      "  ✓ 섹션: 151개\n",
      "[35/100] 처리 중: 수협중앙회_강릉어선안전조업국 상황관제시스템 구축.pdf\n",
      "  ✓ 검색 항목: 638개\n",
      "  ✓ 섹션: 98개\n",
      "[36/100] 처리 중: 남서울대학교_[혁신-국고] 남서울대학교 스마트 정보시스템 활성화(학사.pdf\n",
      "  ✓ 검색 항목: 1291개\n",
      "  ✓ 섹션: 181개\n",
      "[37/100] 처리 중: 그랜드코리아레저(주)_2024년도 GKL  그룹웨어 시스템 구축 용역.pdf\n",
      "  ✓ 검색 항목: 2120개\n",
      "  ✓ 섹션: 165개\n",
      "[38/100] 처리 중: 한국농어촌공사_아세안+3 식량안보정보시스템(AFSIS) 3단계 협력(캄보디아.pdf\n",
      "  ✓ 검색 항목: 1562개\n",
      "  ✓ 섹션: 211개\n",
      "[39/100] 처리 중: 한국로봇산업진흥원_한국로봇산업진흥원 사업관리시스템 온라인평가 .pdf\n",
      "  ✓ 검색 항목: 846개\n",
      "  ✓ 섹션: 116개\n",
      "[40/100] 처리 중: 사단법인아시아물위원회사무국_우즈벡-키르기즈스탄 기후변화대응 스.pdf\n",
      "  ✓ 검색 항목: 824개\n",
      "  ✓ 섹션: 158개\n",
      "[41/100] 처리 중: 한국재정정보원_e나라도움 업무시스템 웹 접근성 컨설팅.pdf\n",
      "  ✓ 검색 항목: 1070개\n",
      "  ✓ 섹션: 164개\n",
      "[42/100] 처리 중: 인천광역시 동구_수도국산달동네박물관 전시해설 시스템 구축(협상에 .pdf\n",
      "  ✓ 검색 항목: 964개\n",
      "  ✓ 섹션: 153개\n",
      "[43/100] 처리 중: 국립중앙의료원_(긴급)「2024년도 차세대 응급의료 상황관리시스템 구축.pdf\n",
      "  ✓ 검색 항목: 1926개\n",
      "  ✓ 섹션: 213개\n",
      "[44/100] 처리 중: 고려대학교_차세대 포털·학사 정보시스템 구축사업.pdf\n",
      "  ✓ 검색 항목: 2832개\n",
      "  ✓ 섹션: 182개\n",
      "[45/100] 처리 중: 조선대학교_(재공고)2024 조선대학교 SW중심대학 사업관리시스템(WeHub) 구.pdf\n",
      "  ✓ 검색 항목: 930개\n",
      "  ✓ 섹션: 121개\n",
      "[46/100] 처리 중: 한국해양조사협회_2024년 항해용 간행물 품질관리 업무보조 시스템 구축.pdf\n",
      "  ✓ 검색 항목: 923개\n",
      "  ✓ 섹션: 152개\n",
      "[47/100] 처리 중: 한국건강가정진흥원_2025년 아이돌봄인력 인적성 검사 정보시스템 운영.pdf\n",
      "  ✓ 검색 항목: 892개\n",
      "  ✓ 섹션: 133개\n",
      "[48/100] 처리 중: 한국연구재단_2024년 기초학문자료센터 시스템 운영 및 연구성과물 DB구.pdf\n",
      "  ✓ 검색 항목: 896개\n",
      "  ✓ 섹션: 150개\n",
      "[49/100] 처리 중: 한국어촌어항공단_한국어촌어항공단 경영관리시스템(ERP·GW) 기능 고도.pdf\n",
      "  ✓ 검색 항목: 1079개\n",
      "  ✓ 섹션: 151개\n",
      "[50/100] 처리 중: 중앙선거관리위원회_2025년도 행정정보시스템 위탁운영사업.pdf\n",
      "  ✓ 검색 항목: 1323개\n",
      "  ✓ 섹션: 216개\n",
      "[51/100] 처리 중: 한국발명진흥회 입찰공고_2024년 건설기술에 관한 특허·실용신안 활용실.pdf\n",
      "  ✓ 검색 항목: 925개\n",
      "  ✓ 섹션: 120개\n",
      "[52/100] 처리 중: 한국생산기술연구원_2세대 전자조달시스템  기반구축사업.pdf\n",
      "  ✓ 검색 항목: 1115개\n",
      "  ✓ 섹션: 136개\n",
      "[53/100] 처리 중: 대검찰청_아태 사이버범죄 역량강화 허브(APC-HUB) 홈페이지 및 온라인 교.pdf\n",
      "  ✓ 검색 항목: 801개\n",
      "  ✓ 섹션: 109개\n",
      "[54/100] 처리 중: 서울특별시 여성가족재단_(재공고, 협상) 서울 디지털성범죄 안심지원센.pdf\n",
      "  ✓ 검색 항목: 1864개\n",
      "  ✓ 섹션: 192개\n",
      "[55/100] 처리 중: 울산광역시_2024년 버스정보시스템 확대 구축 및 기능개선 용역.pdf\n",
      "  ✓ 검색 항목: 1187개\n",
      "  ✓ 섹션: 150개\n",
      "[56/100] 처리 중: 한국지식재산보호원_IP-NAVI  해외지식재산센터 사업관리 시스템 기능개.pdf\n",
      "  ✓ 검색 항목: 1031개\n",
      "  ✓ 섹션: 151개\n",
      "[57/100] 처리 중: 한국보육진흥원_연차별 자율 품질관리 시스템 기능개선.pdf\n",
      "  ✓ 검색 항목: 833개\n",
      "  ✓ 섹션: 83개\n",
      "[58/100] 처리 중: 한국연구재단_2024년 대학산학협력활동 실태조사 시스템(UICC) 기능개선.pdf\n",
      "  ✓ 검색 항목: 1071개\n",
      "  ✓ 섹션: 140개\n",
      "[59/100] 처리 중: 재단법인충북연구원_GIS통계 기반 재난안전데이터 분석ㆍ관리 시스템 구.pdf\n",
      "  ✓ 검색 항목: 753개\n",
      "  ✓ 섹션: 110개\n",
      "[60/100] 처리 중: 한국수자원조사기술원_수문자료정보관리시스템(HDIMS) 재구축 용역(3단계.pdf\n",
      "  ✓ 검색 항목: 1094개\n",
      "  ✓ 섹션: 145개\n",
      "[61/100] 처리 중: 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf\n",
      "  ✓ 검색 항목: 1620개\n",
      "  ✓ 섹션: 168개\n",
      "[62/100] 처리 중: 한국보건산업진흥원_의료기기산업 종합정보시스템(정보관리기관) 기능.pdf\n",
      "  ✓ 검색 항목: 1146개\n",
      "  ✓ 섹션: 128개\n",
      "[63/100] 처리 중: 한국사회보장정보원_라오스 보건의료정보화 협력을 위한 사전타당성 조.pdf\n",
      "  ✓ 검색 항목: 765개\n",
      "  ✓ 섹션: 128개\n",
      "[64/100] 처리 중: 2025 구미 아시아육상경기선수권대회 조직위원회_2025 구미아시아육상경.pdf\n",
      "  ✓ 검색 항목: 505개\n",
      "  ✓ 섹션: 96개\n",
      "[65/100] 처리 중: 한국교육과정평가원_국가교육과정정보센터(NCIC) 시스템 운영 및 개선.pdf\n",
      "  ✓ 검색 항목: 673개\n",
      "  ✓ 섹션: 103개\n",
      "[66/100] 처리 중: 한국철도공사 (용역)_예약발매시스템 개량 ISMP 용역.pdf\n",
      "  ✓ 검색 항목: 1157개\n",
      "  ✓ 섹션: 147개\n",
      "[67/100] 처리 중: 국가철도공단_철도인프라 디지털트윈 정보화전략계획(ISP) 수립 용역(변.pdf\n",
      "  ✓ 검색 항목: 923개\n",
      "  ✓ 섹션: 135개\n",
      "[68/100] 처리 중: BioIN_의료기기산업 종합정보시스템(정보관리기관) 기능개선 사업(2차).pdf\n",
      "  ✓ 검색 항목: 1146개\n",
      "  ✓ 섹션: 128개\n",
      "[69/100] 처리 중: 한국사학진흥재단_대학재정정보시스템(기본재산 및 기채 사후관리) 고.pdf\n",
      "  ✓ 검색 항목: 1453개\n",
      "  ✓ 섹션: 174개\n",
      "[70/100] 처리 중: 인천광역시_인천일자리플랫폼 정보시스템 구축 ISP 수립용역.pdf\n",
      "  ✓ 검색 항목: 750개\n",
      "  ✓ 섹션: 164개\n",
      "[71/100] 처리 중: 재단법인 한국장애인문화예술원_2024년 장애인문화예술정보시스템 이음.pdf\n",
      "  ✓ 검색 항목: 691개\n",
      "  ✓ 섹션: 106개\n",
      "[72/100] 처리 중: 문화체육관광부 국립민속박물관_2024년 국립민속박물관 민속아카이브 자.pdf\n",
      "  ✓ 검색 항목: 932개\n",
      "  ✓ 섹션: 141개\n",
      "[73/100] 처리 중: 재단법인경기도일자리재단_2025년 통합접수시스템 운영.pdf\n",
      "  ✓ 검색 항목: 1673개\n",
      "  ✓ 섹션: 152개\n",
      "[74/100] 처리 중: KOICA 전자조달_[긴급] [지문] [국제] 우즈베키스탄 열린 의정활동 상하원 .pdf\n",
      "  ✓ 검색 항목: 1930개\n",
      "  ✓ 섹션: 196개\n",
      "[75/100] 처리 중: 인천광역시_도시계획위원회 통합관리시스템 구축용역.pdf\n",
      "  ✓ 검색 항목: 990개\n",
      "  ✓ 섹션: 114개\n",
      "[76/100] 처리 중: 한국농어촌공사_네팔 수자원관리 정보화사업-Pilot 시스템 구축용역.pdf\n",
      "  ✓ 검색 항목: 1452개\n",
      "  ✓ 섹션: 163개\n",
      "[77/100] 처리 중: 고양도시관리공사_관산근린공원 다목적구장 홈페이지 및 회원 통합운영.pdf\n",
      "  ✓ 검색 항목: 950개\n",
      "  ✓ 섹션: 145개\n",
      "[78/100] 처리 중: 경기도 안양시_호계체육관 배드민턴장 및 탁구장 예약시스템 구축 용역.pdf\n",
      "  ✓ 검색 항목: 943개\n",
      "  ✓ 섹션: 167개\n",
      "[79/100] 처리 중: 한국산업단지공단_산단 안전정보시스템 1차 구축 용역.pdf\n",
      "  ✓ 검색 항목: 1380개\n",
      "  ✓ 섹션: 136개\n",
      "[80/100] 처리 중: 한국한의학연구원_통합정보시스템 고도화 용역.pdf\n",
      "  ✓ 검색 항목: 931개\n",
      "  ✓ 섹션: 115개\n",
      "[81/100] 처리 중: (재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅.pdf\n",
      "  ✓ 검색 항목: 669개\n",
      "  ✓ 섹션: 120개\n",
      "[82/100] 처리 중: 한국생산기술연구원_EIP3.0 고압가스 안전관리 시스템 구축 용역.pdf\n",
      "  ✓ 검색 항목: 1519개\n",
      "  ✓ 섹션: 180개\n",
      "[83/100] 처리 중: 수협중앙회_수협중앙회 수산물사이버직매장 시스템 재구축 ISMP 수립 입.pdf\n",
      "  ✓ 검색 항목: 911개\n",
      "  ✓ 섹션: 137개\n",
      "[84/100] 처리 중: 한국철도공사 (용역)_[재공고][긴급][협상형]운행정보기록 자동분석시스.pdf\n",
      "  ✓ 검색 항목: 1463개\n",
      "  ✓ 섹션: 169개\n",
      "[85/100] 처리 중: 국방과학연구소_기록관리시스템 통합 활용 및 보안 환경 구축.pdf\n",
      "  ✓ 검색 항목: 872개\n",
      "  ✓ 섹션: 113개\n",
      "[86/100] 처리 중: 재단법인 광주연구원_광주정책연구아카이브(GPA) 시스템 개발.pdf\n",
      "  ✓ 검색 항목: 1043개\n",
      "  ✓ 섹션: 164개\n",
      "[87/100] 처리 중: 한국산업인력공단_RFID기반 국가자격 시험 결과물 스마트 관리시스템 도.pdf\n",
      "  ✓ 검색 항목: 633개\n",
      "  ✓ 섹션: 73개\n",
      "[88/100] 처리 중: 광주과학기술원_실시간통합연구비관리시스템(RCMS)  연계 모듈 변경 사업.pdf\n",
      "  ✓ 검색 항목: 858개\n",
      "  ✓ 섹션: 161개\n",
      "[89/100] 처리 중: 한영대학_한영대학교 특성화 맞춤형 교육환경 구축 - 트랙운영 학사정보.pdf\n",
      "  ✓ 검색 항목: 795개\n",
      "  ✓ 섹션: 108개\n",
      "[90/100] 처리 중: 재단법인 광주광역시 광주문화재단_2024년 광주문화예술통합플랫폼 시스.pdf\n",
      "  ✓ 검색 항목: 907개\n",
      "  ✓ 섹션: 138개\n",
      "[91/100] 처리 중: 서울시립대학교_[사전공개] 학업성취도 다차원 종단분석 통합시스템 1차.pdf\n",
      "  ✓ 검색 항목: 1885개\n",
      "  ✓ 섹션: 241개\n",
      "[92/100] 처리 중: 케빈랩 주식회사_평택시 강소형 스마트시티 AI 기반의 영상감시 시스템 .pdf\n",
      "  ✓ 검색 항목: 869개\n",
      "  ✓ 섹션: 149개\n",
      "[93/100] 처리 중: 국방과학연구소_대용량 자료전송시스템 고도화.pdf\n",
      "  ✓ 검색 항목: 834개\n",
      "  ✓ 섹션: 108개\n",
      "[94/100] 처리 중: 광주과학기술원_학사시스템 기능개선 사업.pdf\n",
      "  ✓ 검색 항목: 594개\n",
      "  ✓ 섹션: 138개\n",
      "[95/100] 처리 중: 전북특별자치도 정읍시_정읍체육트레이닝센터 통합운영관리시스템 구.pdf\n",
      "  ✓ 검색 항목: 1352개\n",
      "  ✓ 섹션: 187개\n",
      "[96/100] 처리 중: 인천공항운영서비스(주)_인천공항운영서비스㈜ 차세대 ERP시스템 구축 .pdf\n",
      "  ✓ 검색 항목: 829개\n",
      "  ✓ 섹션: 72개\n",
      "[97/100] 처리 중: 경상북도 봉화군_봉화군 재난통합관리시스템 고도화 사업(협상)(긴급).pdf\n",
      "  ✓ 검색 항목: 753개\n",
      "  ✓ 섹션: 122개\n",
      "[98/100] 처리 중: 축산물품질평가원_꿀 품질평가 전산시스템 기능개선 사업.pdf\n",
      "  ✓ 검색 항목: 977개\n",
      "  ✓ 섹션: 136개\n",
      "[99/100] 처리 중: 한국전기안전공사_전기안전 관제시스템 보안 모듈 개발 용역.pdf\n",
      "  ✓ 검색 항목: 886개\n",
      "  ✓ 섹션: 113개\n",
      "[100/100] 처리 중: 한국가스공사_[재공고]차세대 통합정보시스템(ERP) 구축.pdf\n",
      "  ✓ 검색 항목: 1673개\n",
      "  ✓ 섹션: 102개\n",
      "\n",
      "================================================================================\n",
      "통합 파일 저장 중...\n",
      "================================================================================\n",
      "✓ all_search_index.json: 108657개 항목\n",
      "✓ all_hierarchies.json: 100개 문서\n",
      "✓ all_metadata.json: 100개 문서\n",
      "✓ processing_report.json\n",
      "\n",
      "================================================================================\n",
      "처리 완료!\n",
      "================================================================================\n",
      "성공: 100/100개\n",
      "실패: 0개\n",
      "\n",
      "통합 검색 항목: 108,657개\n",
      "총 섹션: 14,200개\n",
      "총 페이지: 9,517개\n",
      "평균 검색 항목/문서: 1087개\n",
      "\n",
      "📁 생성된 파일:\n",
      "  - /Users/won/dev/00_codeit/0_mission/200_DL_RAG/data/all_search_index.json ⭐\n",
      "  - /Users/won/dev/00_codeit/0_mission/200_DL_RAG/data/all_hierarchies.json\n",
      "  - /Users/won/dev/00_codeit/0_mission/200_DL_RAG/data/all_metadata.json\n",
      "  - /Users/won/dev/00_codeit/0_mission/200_DL_RAG/data/processing_report.json\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def process_all_pdfs(pdf_dir, output_dir, doc_converter, save_individual=False):\n",
    "    \"\"\"\n",
    "    100개 PDF 일괄 처리 (통합 파일 중심)\n",
    "    \n",
    "    Args:\n",
    "        pdf_dir: PDF 디렉토리\n",
    "        output_dir: 출력 디렉토리\n",
    "        doc_converter: Docling 변환기\n",
    "        save_individual: 개별 파일 저장 여부 (기본: False)\n",
    "    \n",
    "    생성 파일:\n",
    "        - all_search_index.json (통합 검색 인덱스) ⭐\n",
    "        - all_hierarchies.json (통합 계층 정보)\n",
    "        - all_metadata.json (통합 메타데이터)\n",
    "        - processing_report.json (처리 리포트)\n",
    "        - individual/*.json (옵션)\n",
    "    \"\"\"\n",
    "    \n",
    "    pdf_files = list(Path(pdf_dir).glob(\"*.pdf\"))\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 개별 파일 저장용 디렉토리\n",
    "    if save_individual:\n",
    "        individual_path = output_path / \"individual\"\n",
    "        individual_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # 클래스 초기화\n",
    "    detector = HierarchyDetector()\n",
    "    cleaner = SearchIndexCleaner()\n",
    "    \n",
    "    # 통합 데이터 저장소\n",
    "    all_search_items = []      # ⭐ 핵심: 모든 검색 항목\n",
    "    all_hierarchies = {}       # 모든 계층 정보\n",
    "    all_metadata = {}          # 모든 메타데이터\n",
    "    \n",
    "    processing_log = {\n",
    "        'start_time': datetime.now().isoformat(),\n",
    "        'total_files': len(pdf_files),\n",
    "        'success_count': 0,\n",
    "        'failed_count': 0,\n",
    "        'failed_files': [],\n",
    "        'statistics': {\n",
    "            'total_search_items': 0,\n",
    "            'total_sections': 0,\n",
    "            'total_pages': 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"PDF 일괄 처리 시작: {len(pdf_files)}개 파일\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    for i, pdf_path in enumerate(pdf_files):\n",
    "        print(f\"[{i+1}/{len(pdf_files)}] 처리 중: {pdf_path.name}\")\n",
    "        \n",
    "        try:\n",
    "            # 단일 PDF 처리\n",
    "            result = process_single_pdf(pdf_path, detector, cleaner, doc_converter)\n",
    "            \n",
    "            if result['success']:\n",
    "                doc_name = pdf_path.stem\n",
    "                data = result['data']\n",
    "                \n",
    "                # 1. 검색 인덱스에 문서 정보 추가 ⭐\n",
    "                for item in data['search_index_cleaned']:\n",
    "                    # 메타데이터에 문서 정보 추가\n",
    "                    item['metadata']['document'] = pdf_path.name\n",
    "                    item['metadata']['document_id'] = doc_name\n",
    "                    \n",
    "                    all_search_items.append(item)\n",
    "                \n",
    "                # 2. 계층 정보 저장\n",
    "                all_hierarchies[doc_name] = {\n",
    "                    'filename': pdf_path.name,\n",
    "                    'hierarchy': data['hierarchy'],\n",
    "                    'tree': data['tree']\n",
    "                }\n",
    "                \n",
    "                # 3. 메타데이터 저장\n",
    "                all_metadata[doc_name] = {\n",
    "                    'filename': pdf_path.name,\n",
    "                    'metadata': data['metadata'],\n",
    "                    'statistics': data['statistics']\n",
    "                }\n",
    "                \n",
    "                # 4. 개별 파일 저장 (옵션)\n",
    "                if save_individual:\n",
    "                    with open(individual_path / f\"{doc_name}_search_index.json\", 'w', encoding='utf-8') as f:\n",
    "                        json.dump(data['search_index_cleaned'], f, ensure_ascii=False, indent=2)\n",
    "                    \n",
    "                    with open(individual_path / f\"{doc_name}_hierarchy.json\", 'w', encoding='utf-8') as f:\n",
    "                        json.dump(all_hierarchies[doc_name], f, ensure_ascii=False, indent=2)\n",
    "                \n",
    "                processing_log['success_count'] += 1\n",
    "                processing_log['statistics']['total_search_items'] += len(data['search_index_cleaned'])\n",
    "                processing_log['statistics']['total_sections'] += data['metadata']['total_sections']\n",
    "                processing_log['statistics']['total_pages'] += data['metadata']['total_pages']\n",
    "                \n",
    "                print(f\"  ✓ 검색 항목: {len(data['search_index_cleaned'])}개\")\n",
    "                print(f\"  ✓ 섹션: {data['metadata']['total_sections']}개\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            processing_log['failed_count'] += 1\n",
    "            processing_log['failed_files'].append({\n",
    "                'filename': pdf_path.name,\n",
    "                'error': str(e)\n",
    "            })\n",
    "            print(f\"  ✗ 실패: {e}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 통합 파일 저장 ⭐\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"통합 파일 저장 중...\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # 1. 통합 검색 인덱스 (가장 중요!)\n",
    "    with open(output_path / 'all_search_index.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_search_items, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"✓ all_search_index.json: {len(all_search_items)}개 항목\")\n",
    "    \n",
    "    # 2. 통합 계층 정보\n",
    "    with open(output_path / 'all_hierarchies.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_hierarchies, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"✓ all_hierarchies.json: {len(all_hierarchies)}개 문서\")\n",
    "    \n",
    "    # 3. 통합 메타데이터\n",
    "    with open(output_path / 'all_metadata.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_metadata, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"✓ all_metadata.json: {len(all_metadata)}개 문서\")\n",
    "    \n",
    "    # 4. 처리 리포트\n",
    "    processing_log['end_time'] = datetime.now().isoformat()\n",
    "    with open(output_path / 'processing_report.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(processing_log, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"✓ processing_report.json\")\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"처리 완료!\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"성공: {processing_log['success_count']}/{processing_log['total_files']}개\")\n",
    "    print(f\"실패: {processing_log['failed_count']}개\")\n",
    "    print(f\"\")\n",
    "    print(f\"통합 검색 항목: {processing_log['statistics']['total_search_items']:,}개\")\n",
    "    print(f\"총 섹션: {processing_log['statistics']['total_sections']:,}개\")\n",
    "    print(f\"총 페이지: {processing_log['statistics']['total_pages']:,}개\")\n",
    "    print(f\"평균 검색 항목/문서: {processing_log['statistics']['total_search_items'] / processing_log['success_count']:.0f}개\")\n",
    "    \n",
    "    if processing_log['failed_files']:\n",
    "        print(f\"\\n⚠️ 실패한 파일:\")\n",
    "        for failed in processing_log['failed_files']:\n",
    "            print(f\"  - {failed['filename']}: {failed['error']}\")\n",
    "    \n",
    "    print(f\"\\n📁 생성된 파일:\")\n",
    "    print(f\"  - {output_path}/all_search_index.json ⭐\")\n",
    "    print(f\"  - {output_path}/all_hierarchies.json\")\n",
    "    print(f\"  - {output_path}/all_metadata.json\")\n",
    "    print(f\"  - {output_path}/processing_report.json\")\n",
    "    if save_individual:\n",
    "        print(f\"  - {output_path}/individual/*.json\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return {\n",
    "        'search_items': all_search_items,\n",
    "        'hierarchies': all_hierarchies,\n",
    "        'metadata': all_metadata,\n",
    "        'report': processing_log\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# 실행\n",
    "# =============================================================================\n",
    "\n",
    "# 권장: 통합 파일만 생성\n",
    "results = process_all_pdfs(RAW_DIR, DATA_DIR, doc_converter, save_individual=False)\n",
    "\n",
    "# 또는: 개별 파일도 저장 (디버깅용)\n",
    "# results = process_all_pdfs(RAW_DIR, DATA_DIR, doc_converter, save_individual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ca096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "200_DL_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
